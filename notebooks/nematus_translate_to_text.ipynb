{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from ochre.utils import align_characters, read_texts, to_space_tokenized\n",
    "\n",
    "def get_sequences(fname):\n",
    "    sentences = []\n",
    "    with open(fname) as f:\n",
    "        for sentence in f:\n",
    "            #print(sentence)\n",
    "            characters = sentence.split()\n",
    "            #print(characters)\n",
    "            s = []\n",
    "            for c in characters:\n",
    "                if c == '<SPACE>':\n",
    "                    s.append(' ')\n",
    "                else:\n",
    "                    s.append(c)\n",
    "            #print(''.join(s))\n",
    "            sentences.append(s)\n",
    "    return sentences\n",
    "\n",
    "def space_tokenize(gs_data, ocr_data, seq_length=53):\n",
    "\n",
    "    num_seqs = 0\n",
    "    equal = 0\n",
    "\n",
    "    for i, (c1, c2) in enumerate(zip(gs_data, ocr_data)):\n",
    "        if i == 0 or (c1 == ' ' and c2 == ' '):\n",
    "            #print(i)\n",
    "            start = i\n",
    "            if i > 0:\n",
    "                start = i + 1\n",
    "            gs = ''.join(gs_data[start:start+seq_length])\n",
    "            ocr = ''.join(ocr_data[start:start+seq_length])\n",
    "        \n",
    "            #print(to_space_tokenized(gs))\n",
    "            #print(to_space_tokenized(ocr))\n",
    "            \n",
    "            yield gs_data[start:start+seq_length], ocr_data[start:start+seq_length]\n",
    "        \n",
    "            if gs == ocr:\n",
    "                equal += 1\n",
    "        \n",
    "            num_seqs += 1\n",
    "    print('num seqs:', num_seqs)\n",
    "    print('equal:', equal)\n",
    "    print('% equal:', equal/num_seqs *100)\n",
    "\n",
    "\n",
    "def convert_to_text(aligned_file, pred_file, empty_char='#'):\n",
    "    pred_seqs = get_sequences(pred_file)\n",
    "    \n",
    "    raw_test, gs_test, ocr_test = read_texts([aligned_file], None)\n",
    "    gs_seqs = []\n",
    "    ocr_seqs = []\n",
    "    for gs_seq, ocr_seq in space_tokenize(gs_test, ocr_test):\n",
    "        gs = []\n",
    "        for c in gs_seq:\n",
    "            if c == '':\n",
    "                gs.append(empty_char)\n",
    "            else:\n",
    "                gs.append(c)\n",
    "                \n",
    "        ocr = []\n",
    "        for c in ocr_seq:\n",
    "            if c == '':\n",
    "                ocr.append(empty_char)\n",
    "            else:\n",
    "                ocr.append(c)\n",
    "                \n",
    "        gs_seqs.append(gs)\n",
    "        ocr_seqs.append(ocr)\n",
    "    \n",
    "    idx = 0\n",
    "    counters = {}\n",
    "    input_counters = {}\n",
    "\n",
    "    for j, (s1, s2, s3) in enumerate(zip(gs_seqs, ocr_seqs, pred_seqs)):\n",
    "        # the final sequence are empty, edlib can't deal with this\n",
    "        if s3 != [] and s2 != []:\n",
    "            #print('  GS:', ''.join(s1))\n",
    "            #print(' OCR:', ''.join(s2))\n",
    "            #print('PRED:', ''.join(s3))\n",
    "            \n",
    "            for i, (c1, c2) in enumerate(zip(s1, s2)):\n",
    "                if c1 == ' ' and c2 == ' ':\n",
    "                    skip = i+1\n",
    "                    break\n",
    "        \n",
    "            # align pred with ocr (input)\n",
    "            ocr, pred, _match = align_characters(s3, s2, empty_char='')\n",
    "            \n",
    "            tmp_pred = []\n",
    "            for c in pred:\n",
    "                if c == '':\n",
    "                    tmp_pred.append(empty_char)\n",
    "                else:\n",
    "                    tmp_pred.append(c)\n",
    "            \n",
    "            \n",
    "            #print('ALIG:', ''.join(tmp_pred))\n",
    "            #print('SKIP:', ' '*(skip-1)+'^')\n",
    "            #print('---')\n",
    "\n",
    "            for i, c in enumerate(pred):\n",
    "                if not idx + i in counters.keys():\n",
    "                    counters[idx+i] = Counter()\n",
    "                counters[idx+i][c] += 1\n",
    "                #print(idx+i, counters[idx+i])\n",
    "            \n",
    "            for i, inp in enumerate(s2):\n",
    "                if not idx + i in input_counters.keys():\n",
    "                    input_counters[idx+i] = Counter()\n",
    "                input_counters[idx+i][inp] += 1\n",
    "                \n",
    "            idx += skip\n",
    "                \n",
    "    agg_out = []\n",
    "    multiple_choices = 0\n",
    "    take_ocr_char = 0\n",
    "    for idx, c in counters.items():\n",
    "        if len(c) > 1:\n",
    "            multiple_choices += 1\n",
    "            opt1, opt2 = c.most_common(2)\n",
    "            if opt1[1] == opt2[1]:\n",
    "                #print('Take OCR char')\n",
    "                #print(c.most_common(2))\n",
    "                \n",
    "                try:\n",
    "                    #print(input_counters[idx])\n",
    "                    selected = input_counters[idx].most_common(1)[0][0]\n",
    "                    if selected == empty_char:\n",
    "                        selected = ''\n",
    "                except KeyError:\n",
    "                    selected = ''\n",
    "                take_ocr_char += 1\n",
    "            else:\n",
    "                selected = opt1[0]\n",
    "        else:\n",
    "            selected = c.most_common(1)[0][0]\n",
    "        \n",
    "        agg_out.append(selected)\n",
    "        \n",
    "            \n",
    "\n",
    "    corrected_text = u''.join(agg_out)\n",
    "    corrected_text = corrected_text.replace(empty_char, u'')\n",
    "    \n",
    "    print(f'{multiple_choices} of {len(counters)} characters have multiple choices')\n",
    "    print(f'{take_ocr_char} of {multiple_choices} have equal most common')\n",
    "    \n",
    "    return corrected_text      \n",
    "\n",
    "gs_file = '/home/jvdzwaan/data/kb-ocr/A8P1/test/DDD_010265237_001.gs'\n",
    "ocr_file = '/home/jvdzwaan/data/kb-ocr/A8P1/test/DDD_010265237_001.ocr'\n",
    "pred_file = '/home/jvdzwaan/data/kb-ocr/A8P1/pred/DDD_010265237_001.pred'\n",
    "aligned_file = '/home/jvdzwaan/data/kb-ocr/text_aligned_blocks-match_gs/aligned/DDD_010265237_001.json'\n",
    "\n",
    "convert_to_text(aligned_file, pred_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "from nlppln.utils import create_dirs, out_file_name\n",
    "\n",
    "def convert_dir_to_text(aligned_dir, pred_dir, out_dir):\n",
    "    create_dirs(out_dir)\n",
    "    \n",
    "    pred_files = sorted(glob.glob(f'{pred_dir}/*.pred'))\n",
    "    \n",
    "    for pred in pred_files:\n",
    "        print(pred)\n",
    "        \n",
    "        bn = os.path.splitext(os.path.basename(pred))[0]\n",
    "        #print(bn)\n",
    "        aligned = os.path.join(aligned_dir, f'{bn}.json')\n",
    "        #print(aligned)\n",
    "        \n",
    "        corrected_text = convert_to_text(aligned, pred)\n",
    "        \n",
    "        # The ocrevaluation tool wants *.txt\n",
    "        out_file = out_file_name(out_dir, pred, ext='txt')\n",
    "        #print(out_file)\n",
    "        with open(out_file, 'w') as f:\n",
    "            f.write(corrected_text)\n",
    "        print()\n",
    "\n",
    "aligned_dir = '/home/jvdzwaan/data/kb-ocr/text_aligned_blocks-match_gs/aligned/'\n",
    "pred_dir = '/home/jvdzwaan/data/kb-ocr/A8P1/pred/'\n",
    "\n",
    "out_dir = '/home/jvdzwaan/data/kb-ocr/text_aligned_blocks-match_gs/pred-A8P1/'\n",
    "\n",
    "convert_dir_to_text(aligned_dir, pred_dir, out_dir)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
