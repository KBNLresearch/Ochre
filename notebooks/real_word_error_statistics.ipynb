{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from ochre.ocrerrors import categorize_errors\n",
    "\n",
    "def count_real_word_errors(csv_file, words):\n",
    "    \n",
    "    \n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "    num_words = df.shape[0]\n",
    "    #print('# words', df.shape[0])\n",
    "    df = df[df.apply(lambda row: row['gs'] != row['ocr'], axis=1)]\n",
    "    #print(df)\n",
    "    num_errors = df.shape[0]\n",
    "    #print('# error words', df.shape[0])\n",
    "    df = df.fillna(u'@@@')\n",
    "    \n",
    "    df = categorize_errors(df, terms=words, gs_name='gs', ocr_name='ocr')\n",
    "    \n",
    "    rwe = df.query('error_type == \"real_word\"')\n",
    "    \n",
    "    #print(rwe)\n",
    "    \n",
    "    rwe_long = int(np.sum(rwe.apply(lambda row: len(row['gs']) >= 6, axis=1)))\n",
    "\n",
    "    return {'words': num_words, \n",
    "            'errors': num_errors, \n",
    "            'real_word_errors': rwe.shape[0], \n",
    "            'long_real_word_errors': rwe_long}\n",
    "\n",
    "csv_file = '/home/jvdzwaan/data/kb-ocr/text_aligned_blocks-match_gs/word-mappings/DDD_000012234_001.csv'\n",
    "lexicon_file = '/home/jvdzwaan/code/ticclat/explore/notebooks/ingest/INL_lexicon.csv'\n",
    "\n",
    "wordforms = pd.read_csv(lexicon_file)\n",
    "words = list(wordforms['wordform'])\n",
    "print(len(words))\n",
    "\n",
    "r = count_real_word_errors(csv_file, words)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlppln.utils import get_files\n",
    "\n",
    "in_dir = '/home/jvdzwaan/data/kb-ocr/text_aligned_blocks-match_gs/word-mappings/'\n",
    "\n",
    "lexicon_file = '/home/jvdzwaan/code/ticclat/explore/notebooks/ingest/INL_lexicon.csv'\n",
    "\n",
    "wordforms = pd.read_csv(lexicon_file)\n",
    "words = list(wordforms['wordform'])\n",
    "\n",
    "result = []\n",
    "\n",
    "for in_file in tqdm(get_files(in_dir)):\n",
    "    try:\n",
    "        r = count_real_word_errors(in_file, words)\n",
    "        result.append(r)\n",
    "    except:\n",
    "        print(in_file)\n",
    "    \n",
    "df = pd.DataFrame(result)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
