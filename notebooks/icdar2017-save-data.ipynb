{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from ochre.utils import read_texts\n",
    "\n",
    "datasets = '/home/jvdzwaan/data/icdar2017st/eng_monograph/datadivision.json'\n",
    "data_dir = '/home/jvdzwaan/data/icdar2017st/eng_monograph/aligned/'\n",
    "\n",
    "with open(datasets) as d:\n",
    "    division = json.load(d)\n",
    "print(len(division['train']))\n",
    "print(len(division['test']))\n",
    "print(len(division['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ochre.utils import get_chars, get_sequences\n",
    "\n",
    "seq_length = 53\n",
    "\n",
    "raw_val, gs_val, ocr_val = read_texts(division.get('val'), data_dir)\n",
    "raw_test, gs_test, ocr_test = read_texts(division.get('test'), data_dir)\n",
    "raw_train, gs_train, ocr_train = read_texts(division.get('train'), data_dir)\n",
    "\n",
    "chars, num_chars, ci = get_chars(raw_val, raw_test, raw_train, False)\n",
    "\n",
    "gs_seqs_val, ocr_seqs_val = get_sequences(gs_val, ocr_val, seq_length)\n",
    "gs_seqs_test, ocr_seqs_test = get_sequences(gs_test, ocr_test, seq_length)\n",
    "gs_seqs_train, ocr_seqs_train = get_sequences(gs_train, ocr_train, seq_length)\n",
    "\n",
    "print('n samples val', len(gs_seqs_val))\n",
    "print('n samples test', len(gs_seqs_test))\n",
    "print('n samples train', len(gs_seqs_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_ocr_space(ocr_text, gs_seqs, ocr_seqs):\n",
    "    ocr_selected = []\n",
    "    gs_selected = []\n",
    "    for i, c in enumerate(ocr_text):\n",
    "        if c == ' ':\n",
    "            if i < len(ocr_text)-1 and ocr_text[i+1] != ' ':\n",
    "                try:\n",
    "                    ocr_selected.append(ocr_seqs[i+1])\n",
    "                    gs_selected.append(gs_seqs[i+1])\n",
    "                    #print(repr(ocr_seqs_test[i+1]))\n",
    "                except IndexError:\n",
    "                    break\n",
    "    return gs_selected, ocr_selected\n",
    "gs_selected_test, ocr_selected_test = filter_ocr_space(ocr_test, gs_seqs_test, ocr_seqs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ocr_train), len(ocr_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gs_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_selected[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_selected[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_selected_test, ocr_selected_test = filter_ocr_space(ocr_test, gs_seqs_test, ocr_seqs_test)\n",
    "gs_selected_train, ocr_selected_train = filter_ocr_space(ocr_train, gs_seqs_train, ocr_seqs_train)\n",
    "gs_selected_val, ocr_selected_val = filter_ocr_space(ocr_val, gs_seqs_val, ocr_seqs_val)\n",
    "\n",
    "print('n samples val', len(gs_selected_val))\n",
    "print('n samples test', len(gs_selected_test))\n",
    "print('n samples train', len(gs_selected_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('train.pkl', 'wb') as f:\n",
    "    pickle.dump((gs_selected_train, ocr_selected_train), f)\n",
    "    \n",
    "with open('val.pkl', 'wb') as f:\n",
    "    pickle.dump((gs_selected_val, ocr_selected_val), f)\n",
    "    \n",
    "with open('ci.pkl', 'wb') as f:\n",
    "    pickle.dump(ci, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocr_seqs_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ochre.datagen import DataGenerator\n",
    "\n",
    "dg_val = DataGenerator(xData=ocr_selected_val, yData=gs_selected_val, char_to_int=ci,\n",
    "                       seq_length=seq_length, padding_char='\\n', oov_char='@',\n",
    "                       batch_size=100, shuffle=False)\n",
    "dg_test = DataGenerator(xData=ocr_selected_test, yData=gs_selected_test, char_to_int=ci,\n",
    "                       seq_length=seq_length, padding_char='\\n', oov_char='@',\n",
    "                       batch_size=100, shuffle=False)\n",
    "dg_train = DataGenerator(xData=ocr_selected_train, yData=gs_selected_train, char_to_int=ci,\n",
    "                       seq_length=seq_length, padding_char='\\n', oov_char='@',\n",
    "                       batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "n_nodes = 1000\n",
    "dropout = 0.2\n",
    "n_embed = 256\n",
    "n_vocab = len(ci)\n",
    "\n",
    "loss='categorical_crossentropy'\n",
    "optimizer='adam'\n",
    "metrics=['accuracy']\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# encoder\n",
    "\n",
    "model.add(Embedding(n_vocab, n_embed, input_length=seq_length))\n",
    "model.add(LSTM(n_nodes, input_shape=(seq_length, n_vocab)))\n",
    "# For the decoder's input, we repeat the encoded input for each time step\n",
    "model.add(RepeatVector(seq_length))\n",
    "model.add(LSTM(n_nodes, return_sequences=True))\n",
    "\n",
    "# For each of step of the output sequence, decide which character should be\n",
    "# chosen\n",
    "model.add(TimeDistributed(Dense(n_vocab, activation='softmax')))\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize saving of weights\n",
    "#filepath = os.path.join(weights_dir, '{loss:.4f}-{epoch:02d}.hdf5')\n",
    "filepath = '{loss:.4f}-{epoch:02d}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1,\n",
    "                                 save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# do training (and save weights)\n",
    "model.fit_generator(dg_train, steps_per_epoch=len(dg_train), epochs=10, \n",
    "                    validation_data=dg_val, \n",
    "                    validation_steps=len(dg_val), callbacks=callbacks_list,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
