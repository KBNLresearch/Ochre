{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('/home/jvdzwaan/data/tmp/ocr/align_metadata.csv', index_col=2, encoding='utf-8')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "with codecs.open('/home/jvdzwaan/Downloads/ocr/BAObi1-ds.ocr.txt', encoding='utf-8') as f:\n",
    "    ocr = f.read()\n",
    "with codecs.open('/home/jvdzwaan/Downloads/ocr/BAObi1-ds.gs.txt', encoding='utf-8') as f:\n",
    "    gs = f.read()\n",
    "print ocr\n",
    "print len(ocr)\n",
    "print '---'\n",
    "print gs\n",
    "print len(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cigar = data['cigar'][0]\n",
    "print cigar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "matches = re.findall(r'(\\d+)(.)', cigar)\n",
    "offset1 = 0\n",
    "offset2 = 0\n",
    "\n",
    "gs_a = []\n",
    "ocr_a = []\n",
    "\n",
    "seq1 = ocr\n",
    "seq2 = gs\n",
    "\n",
    "empty_char = ''\n",
    "\n",
    "for m in matches:\n",
    "    n = int(m[0])\n",
    "    typ = m[1]\n",
    "\n",
    "    if typ == '=':\n",
    "        # sanity check - strings should be equal\n",
    "        assert(seq1[offset1:offset1+n] == seq2[offset2:offset2+n])\n",
    "\n",
    "        for c in seq1[offset1:offset1+n]:\n",
    "            ocr_a.append(c)\n",
    "        for c in seq2[offset2:offset2+n]:\n",
    "            gs_a.append(c)\n",
    "        \n",
    "        offset1 += n\n",
    "        offset2 += n\n",
    "    elif typ == 'D':  # Inserted\n",
    "        for _ in range(n):\n",
    "            ocr_a.append(empty_char)\n",
    "        for c in seq2[offset2:offset2+n]:\n",
    "            gs_a.append(c)\n",
    "\n",
    "        offset2 += n\n",
    "    elif typ == 'X':\n",
    "        for c in seq1[offset1:offset1+n]:\n",
    "            ocr_a.append(c)\n",
    "        for c in seq2[offset2:offset2+n]:\n",
    "            gs_a.append(c)\n",
    "\n",
    "        offset1 += n\n",
    "        offset2 += n\n",
    "    elif typ == 'I':  # Deleted\n",
    "        for c in seq1[offset1:offset1+n]:\n",
    "            ocr_a.append(c)\n",
    "        for _ in range(n):\n",
    "            gs_a.append(empty_char)\n",
    "\n",
    "        offset1 += n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(ocr_a), len(gs_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in zip(ocr_a, gs_a):\n",
    "    print i, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = ' '.join([''.join(ocr_a), ''.join(gs_a)])\n",
    "\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))    \n",
    "\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print \"Total Characters: \", n_chars\n",
    "print \"Total Vocab: \", n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print char_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_data(ocr_texts, gs_texts, seq_length=25):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for ocr, gs in zip(ocr_texts, gs_texts):\n",
    "        text_length = len(ocr)\n",
    "        for i in range(0, text_length-seq_length +1, 1):\n",
    "            seq_in = ocr[i:i+seq_length]\n",
    "            seq_out = gs[i:i+seq_length]\n",
    "            dataX.append(''.join(seq_in))\n",
    "            dataY.append(''.join(seq_out))\n",
    "            print dataX[-1], dataY[-1]\n",
    "        \n",
    "    X = np.zeros((len(dataX), seq_length, n_vocab), dtype=np.bool)\n",
    "    Y = np.zeros((len(dataY), seq_length, n_vocab), dtype=np.bool)\n",
    "\n",
    "    #for i, sentence in enumerate(dataX):\n",
    "        #print sentence\n",
    "    #    for j, c in enumerate(sentence):\n",
    "    #        X[i, j, char_to_int[c]] = 1\n",
    "        #print X[i]\n",
    "        #print X[i].shape\n",
    "\n",
    "    #for i, sentence in enumerate(dataY):\n",
    "        #print sentence\n",
    "    #    for j, c in enumerate(sentence):\n",
    "    #        Y[i, j, char_to_int[c]] = 1\n",
    "        #print Y[i]\n",
    "        #print Y[i].shape\n",
    "    return X, Y\n",
    "\n",
    "X, Y = create_data([ocr_a], [gs_a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print X.shape"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
