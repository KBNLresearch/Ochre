{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# get test set\n",
    "with codecs.open('/home/jvdzwaan/data/ocr/datadivision.json', encoding='utf-8') as f:\n",
    "    division = json.load(f)\n",
    "print division.get('test')\n",
    "print len(division.get('test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 25\n",
    "num_nodes = 256\n",
    "layers = 1\n",
    "batch_size = 100\n",
    "lowercase = True\n",
    "bidirectional = True\n",
    "data_dir = '/home/jvdzwaan/data/ocr'\n",
    "weights_dir = '/home/jvdzwaan/data/ocr-all-bidirect/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_texts(data_files, data_dir):\n",
    "    raw_text = []\n",
    "    gs = []\n",
    "    ocr = []\n",
    "\n",
    "    for df in data_files:\n",
    "        with codecs.open(os.path.join(data_dir, df), encoding='utf-8') as f:\n",
    "            aligned = json.load(f)\n",
    "\n",
    "        ocr.append(aligned['ocr'])\n",
    "        ocr.append([' ']) # add space between two texts\n",
    "        gs.append(aligned['gs'])\n",
    "        gs.append([' ']) # add space between two texts\n",
    "\n",
    "        raw_text.append(''.join(aligned['ocr']))\n",
    "        raw_text.append(''.join(aligned['gs']))\n",
    "\n",
    "    # Make a single array, containing the character-aligned text of all data\n",
    "    # files\n",
    "    gs_text = [y for x in gs for y in x]\n",
    "    ocr_text = [y for x in ocr for y in x]\n",
    "\n",
    "    return ' '.join(raw_text), gs_text, ocr_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_to_int(chars):\n",
    "    return dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "\n",
    "def get_int_to_char(chars):\n",
    "    return dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_val, gs_val, ocr_val = read_texts(division.get('val'), data_dir)\n",
    "raw_test, gs_test, ocr_test = read_texts(division.get('test'), data_dir)\n",
    "raw_train, gs_train, ocr_train = read_texts(division.get('train'), data_dir)\n",
    "\n",
    "raw_text = ''.join([raw_val, raw_test, raw_train])\n",
    "if lowercase:\n",
    "    raw_text = raw_text.lower()\n",
    "\n",
    "chars = sorted(list(set(raw_text)))\n",
    "chars.append(u'\\n')                      # padding character\n",
    "char_to_int = get_char_to_int(chars)\n",
    "\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "\n",
    "print('Total Characters: {}'.format(n_chars))\n",
    "print('Total Vocab: {}'.format(n_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_string(char_list, lowercase):\n",
    "    if lowercase:\n",
    "        return u''.join(char_list).lower()\n",
    "    return u''.join(char_list)\n",
    "\n",
    "\n",
    "def create_synced_data(ocr_text, gs_text, char_to_int, n_vocab, seq_length=25,\n",
    "                       batch_size=100, padding_char=u'\\n', lowercase=False):\n",
    "    \"\"\"Create padded one-hot encoded data sets from text.\n",
    "\n",
    "    A sample consists of seq_length characters from ocr_text\n",
    "    (includes empty characters) (input), and seq_length characters from\n",
    "    gs_text (includes empty characters) (output).\n",
    "    ocr_text and gs_tetxt contain aligned arrays of characters.\n",
    "    Because of the empty characters ('' in the character arrays), the input\n",
    "    and output sequences may not have equal length. Therefore input and\n",
    "    output are padded with a padding character (newline).\n",
    "\n",
    "    Returns:\n",
    "      int: the number of samples in the dataset\n",
    "      generator: generator for one-hot encoded data (so the data doesn't have\n",
    "        to fit in memory)\n",
    "    \"\"\"\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    text_length = len(ocr_text)\n",
    "    for i in range(0, text_length-seq_length + 1, 1):\n",
    "        seq_in = ocr_text[i:i+seq_length]\n",
    "        seq_out = gs_text[i:i+seq_length]\n",
    "        dataX.append(to_string(seq_in, lowercase))\n",
    "        dataY.append(to_string(seq_out, lowercase))\n",
    "    return len(dataX), synced_data_gen(dataX, dataY, seq_length, n_vocab,\n",
    "                                       char_to_int, batch_size, padding_char)\n",
    "\n",
    "\n",
    "def synced_data_gen(dataX, dataY, seq_length, n_vocab, char_to_int, batch_size,\n",
    "                    padding_char):\n",
    "    while 1:\n",
    "        for batch_idx in range(0, len(dataX), batch_size):\n",
    "            X = np.zeros((batch_size, seq_length, n_vocab), dtype=np.bool)\n",
    "            Y = np.zeros((batch_size, seq_length, n_vocab), dtype=np.bool)\n",
    "            sliceX = dataX[batch_idx:batch_idx+batch_size]\n",
    "            sliceY = dataY[batch_idx:batch_idx+batch_size]\n",
    "            for i, (sentenceX, sentenceY) in enumerate(zip(sliceX, sliceY)):\n",
    "                for j, c in enumerate(sentenceX):\n",
    "                    X[i, j, char_to_int[c]] = 1\n",
    "                for j in range(seq_length-len(sentenceX)):\n",
    "                    X[i, len(sentenceX) + j, char_to_int[padding_char]] = 1\n",
    "                for j, c in enumerate(sentenceY):\n",
    "                    Y[i, j, char_to_int[c]] = 1\n",
    "                for j in range(seq_length-len(sentenceY)):\n",
    "                    Y[i, len(sentenceY) + j, char_to_int[padding_char]] = 1\n",
    "            yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTestSamples, testDataGen = create_synced_data(ocr_test, gs_test, char_to_int, n_vocab, seq_length=seq_length, batch_size=batch_size, lowercase=lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_bidirectional(n, dropout, seq_length, chars, output_size,\n",
    "                                   layers, loss='categorical_crossentropy',\n",
    "                                   optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(n, return_sequences=True),\n",
    "                            input_shape=(seq_length, len(chars))))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    for _ in range(layers-1):\n",
    "        model.add(Bidirectional(LSTM(n, return_sequences=True)))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(TimeDistributed(Dense(len(chars), activation='softmax')))\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def load_weights(model, weights_dir, loss='categorical_crossentropy',\n",
    "                 optimizer='adam'):\n",
    "    epoch = 0\n",
    "    weight_files = glob2.glob('{}{}*.hdf5'.format(weights_dir, os.sep))\n",
    "    if weight_files != []:\n",
    "        fname = sorted(weight_files)[0]\n",
    "        print('Loading weights from {}'.format(fname))\n",
    "\n",
    "        model.load_weights(fname)\n",
    "        model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        m = re.match(r'.+-(\\d\\d).hdf5', fname)\n",
    "        if m:\n",
    "            epoch = int(m.group(1))\n",
    "\n",
    "    return epoch, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "import glob2\n",
    "import re\n",
    "\n",
    "model = initialize_model_bidirectional(num_nodes, 0.5, seq_length, chars, n_vocab, layers)\n",
    "epoch, model = load_weights(model, weights_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = get_int_to_char(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTestSamples, testDataGen = create_synced_data(ocr_test, gs_test, char_to_int, n_vocab, seq_length=seq_length, batch_size=batch_size, lowercase=lowercase)\n",
    "\n",
    "xTest = np.zeros((numTestSamples, seq_length, n_vocab))\n",
    "yTest = np.zeros((numTestSamples, seq_length, n_vocab))\n",
    "\n",
    "steps = 0\n",
    "idx = 0\n",
    "for xBatch, yBatch in testDataGen:\n",
    "    for x, y in zip(xBatch, yBatch):\n",
    "        if idx < numTestSamples:\n",
    "            xTest[idx, :, :] = x\n",
    "            yTest[idx, :, :] = y\n",
    "        idx+=1\n",
    "        \n",
    "    if steps == int(numTestSamples/batch_size):\n",
    "        break\n",
    "    steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data(data):\n",
    "    res = data.sum(axis=2)\n",
    "    b = np.ones(res.shape, dtype=np.int)\n",
    "    \n",
    "    return (res==b).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print check_data(xTest), check_data(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(xTest, verbose=1)\n",
    "print predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = 0\n",
    "no_match = 0\n",
    "in_is_out = 0\n",
    "change_correctly_predicted = 0\n",
    "change = False\n",
    "inputs = []\n",
    "gs_strs = []\n",
    "outputs = []\n",
    "\n",
    "\n",
    "for i, sequence in enumerate(predicted):\n",
    "    predicted_indices = [np.random.choice(n_vocab, p=p) for p in sequence]\n",
    "    indices = np.where(yTest[i:i+1,:,:]==True)[2]\n",
    "    indices2 = np.where(xTest[i:i+1,:,:]==True)[2]\n",
    "    pred_str = u''.join([int_to_char[j] for j in predicted_indices])\n",
    "    pred_str = pred_str.replace(u'\\n', u'@')\n",
    "    outputs.append(pred_str)\n",
    "        \n",
    "    gs = u''.join([int_to_char[j] for j in indices])\n",
    "    gs = gs.replace(u'\\n', u'@')\n",
    "    gs_strs.append(gs)\n",
    "        \n",
    "    inp = u''.join([int_to_char[j] for j in indices2])\n",
    "    inp = inp.replace(u'\\n', u'@')\n",
    "    inputs.append(inp)\n",
    "    #print pred_str\n",
    "    #print gs\n",
    "    if list(indices) == list(indices2):\n",
    "        in_is_out += 1\n",
    "        change = False\n",
    "    else:\n",
    "        change = True\n",
    "    \n",
    "    if predicted_indices != list(indices):\n",
    "        no_match += 1\n",
    "        #print u'\"{}\"\\t\"{}\"\\t\"{}\"'.format(inp, gs, pred_str)\n",
    "    else:\n",
    "        match += 1\n",
    "        if change:\n",
    "            change_correctly_predicted += 1\n",
    "        \n",
    "print 'Match', match\n",
    "print 'No match', no_match\n",
    "print 'Input == output', in_is_out\n",
    "print 'Correct when input != output', change_correctly_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print numTestSamples\n",
    "print match + no_match\n",
    "print numTestSamples-in_is_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gs, inp, outp in zip(gs_strs, inputs, outputs):\n",
    "    print u'\"{}\"\\t\"{}\"\\t\"{}\"'.format(inp, gs, outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "num = 550\n",
    "\n",
    "idx = 0\n",
    "counters = {}\n",
    "counters_gs = {}\n",
    "\n",
    "for input_str, output_str, gs_str in zip(inputs[:num], outputs[:num], gs_strs[:num]):\n",
    "    print len(input_str), len(output_str), len(gs_str)\n",
    "    for i, (inp, outp, gs) in enumerate(zip(input_str, output_str, gs_str)):\n",
    "        #print i, inp, outp\n",
    "        if outp != '@':\n",
    "            if not idx + i in counters.keys():\n",
    "                counters[idx+i] = Counter()\n",
    "            counters[idx+i][outp] += 1\n",
    "        \n",
    "        if gs != '@':\n",
    "            if not idx + i in counters_gs.keys():\n",
    "                counters_gs[idx+i] = Counter()\n",
    "            counters_gs[idx+i][gs] += 1\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, c in counters.items():\n",
    "    print sum(c.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print counters_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, c in counters_gs.items():\n",
    "    if len(c) > 2:\n",
    "        print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_out = []\n",
    "\n",
    "for idx, c in counters.items():\n",
    "    agg_out.append(c.most_common(1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ''.join(gs_test[0:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ''.join(agg_out)\n",
    "print\n",
    "print ''.join(raw_test[:num*2])\n",
    "print\n",
    "print ''.join(gs_test[:num*2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_out = []\n",
    "\n",
    "for idx, c in counters_gs.items():\n",
    "    agg_out.append(c.most_common(1)[0][0])\n",
    "print ''.join(agg_out[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chars_per_text = 5000\n",
    "i = num_chars_per_text\n",
    "prev_i = -1\n",
    "indices = []\n",
    "while i < len(gs_test):\n",
    "    if gs_test[i] == '.' and gs_test[i+1] == ' ':\n",
    "        print i\n",
    "        print ''.join(gs_test[prev_i+1:i+1])\n",
    "        indices.append(i+1)\n",
    "        prev_i = i\n",
    "        i += num_chars_per_text\n",
    "    i = i+1\n",
    "print ''.join(gs_test[prev_i+1:])\n",
    "print indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edlib\n",
    "import unicodedata\n",
    "from ochre.char_align import align_characters\n",
    "\n",
    "def align_output_to_input(input_str, output_str, empty_char=u'@'):\n",
    "    #print type(input_str)\n",
    "    #print type(output_str)\n",
    "    #print\n",
    "    # remove accented and other special characters, because edlib doesn't like them (this might be a python 2 problem)\n",
    "    #print output_str.encode('ASCII', 'replace')\n",
    "    #print input_str.encode('ASCII', 'replace')\n",
    "    t_output_str = output_str.encode('ASCII', 'replace')\n",
    "    t_input_str = input_str.encode('ASCII', 'replace')\n",
    "    #print t_output_str, len(t_output_str)\n",
    "    #print t_input_str, len(t_input_str)\n",
    "    #print\n",
    "    try:\n",
    "        r = edlib.align(t_input_str, t_output_str, task='path')\n",
    "    except:\n",
    "        print input_str\n",
    "        print output_str\n",
    "    r1, r2 = align_characters(input_str, output_str, r.get('cigar'), empty_char=empty_char, sanity_check=False)\n",
    "    #print r1\n",
    "    #print r2\n",
    "    #print \n",
    "    #print u''.join(r1)\n",
    "    #print u''.join(r2)\n",
    "    #print \n",
    "    #print len(r2)\n",
    "    #print len(r1)\n",
    "    while len(r2) < len(input_str):\n",
    "        r2.append(u'@')\n",
    "    return u''.join(r2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print align_output_to_input(u'«b««««àà', u'««««a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import edlib\n",
    "from ochre.char_align import align_characters\n",
    "from nlppln.utils import remove_ext\n",
    "\n",
    "inputs = []\n",
    "gs_strs = []\n",
    "outputs = []\n",
    "outputs2 = []\n",
    "\n",
    "for text in division.get('test'):\n",
    "    raw_test, gs_test, ocr_test = read_texts([text], data_dir)\n",
    "    \n",
    "    numTestSamples, testDataGen = create_synced_data(ocr_test, gs_test, char_to_int, n_vocab, seq_length=seq_length, batch_size=batch_size, lowercase=lowercase)\n",
    "\n",
    "    xTest = np.zeros((numTestSamples, seq_length, n_vocab))\n",
    "    yTest = np.zeros((numTestSamples, seq_length, n_vocab))\n",
    "\n",
    "    steps = 0\n",
    "    idx = 0\n",
    "    for xBatch, yBatch in testDataGen:\n",
    "        for x, y in zip(xBatch, yBatch):\n",
    "            if idx < numTestSamples:\n",
    "                xTest[idx, :, :] = x\n",
    "                yTest[idx, :, :] = y\n",
    "            idx+=1\n",
    "        \n",
    "        if steps == int(numTestSamples/batch_size):\n",
    "            break\n",
    "        steps += 1\n",
    "    \n",
    "    predicted = model.predict(xTest, verbose=1)\n",
    "    \n",
    "    match = 0\n",
    "    no_match = 0\n",
    "    in_is_out = 0\n",
    "    inputs = []\n",
    "    gs_strs = []\n",
    "    outputs = []\n",
    "\n",
    "    for i, sequence in enumerate(predicted):\n",
    "        predicted_indices = [np.random.choice(n_vocab, p=p) for p in sequence]\n",
    "        indices = np.where(yTest[i:i+1,:,:]==True)[2]\n",
    "        indices2 = np.where(xTest[i:i+1,:,:]==True)[2]\n",
    "        pred_str = u''.join([int_to_char[j] for j in predicted_indices])\n",
    "        pred_str = pred_str.replace(u'\\n', u'@')\n",
    "        outputs.append(pred_str)\n",
    "        \n",
    "        gs = u''.join([int_to_char[j] for j in indices])\n",
    "        gs = gs.replace(u'\\n', u'@')\n",
    "        gs_strs.append(gs)\n",
    "        \n",
    "        inp = u''.join([int_to_char[j] for j in indices2])\n",
    "        inp = inp.replace(u'\\n', u'@')\n",
    "        inputs.append(inp)\n",
    "        #print pred_str\n",
    "        #print gs\n",
    "        if predicted_indices != list(indices):\n",
    "            no_match += 1\n",
    "            #print u'\"{}\"\\t\"{}\"\\t\"{}\"'.format(inp, gs, pred_str)\n",
    "        else:\n",
    "            match += 1\n",
    "\n",
    "        if list(indices) == list(indices2):\n",
    "            in_is_out += 1\n",
    "     \n",
    "    print\n",
    "    print 'Match', match\n",
    "    print 'No match', no_match\n",
    "    print 'Input == output', in_is_out\n",
    "\n",
    "    idx = 0\n",
    "    counters = {}\n",
    "    counters_gs = {}\n",
    "    prev_output_str = ''\n",
    "\n",
    "    for input_str, output_str, gs_str in zip(inputs, outputs, gs_strs):\n",
    "        #print len(input_str), len(output_str), len(gs_str)\n",
    "        #print input_str, '\\t', gs_str, '\\t', output_str \n",
    "        #print type(output_str.replace('@', ''))\n",
    "        if '@' in output_str:\n",
    "            output_str2 = align_output_to_input(input_str, output_str.replace('@', ''), empty_char=u'@')\n",
    "        else:\n",
    "            output_str2 = output_str\n",
    "        outputs2.append(output_str2)\n",
    "        for i, (inp, outp, gs) in enumerate(zip(input_str, output_str2, gs_str)):\n",
    "            #print i, inp, outp\n",
    "            #if outp != '@':\n",
    "            if not idx + i in counters.keys():\n",
    "                counters[idx+i] = Counter()\n",
    "            counters[idx+i][outp] += 1\n",
    "        \n",
    "            #if gs != '@':\n",
    "            if not idx + i in counters_gs.keys():\n",
    "                counters_gs[idx+i] = Counter()\n",
    "            counters_gs[idx+i][gs] += 1\n",
    "        idx += 1\n",
    "        \n",
    "    agg_out = []\n",
    "    for idx, c in counters.items():\n",
    "        agg_out.append(c.most_common(1)[0][0])\n",
    "     \n",
    "    agg_out_gs = []\n",
    "    for idx, c in counters_gs.items():\n",
    "        agg_out_gs.append(c.most_common(1)[0][0])\n",
    "        \n",
    "    new_text = u''.join(agg_out)\n",
    "    new_text = new_text.replace(u'@', u'')\n",
    "    #print new_text\n",
    "    \n",
    "    fname = remove_ext(text)\n",
    "    fname = '{}-1x256-bidirect-all.txt'.format(fname)\n",
    "    #print fname\n",
    "    with codecs.open(os.path.join('/home/jvdzwaan/data/results-1x256-bidirect-all', fname), 'wb', encoding='utf-8') as f:\n",
    "        f.write(new_text)\n",
    "    #print ''.join(agg_out)\n",
    "    #print \n",
    "    #print ''.join(ocr_test)\n",
    "    #print\n",
    "    #print ''.join(gs_test)\n",
    "    #print \n",
    "    #print ''.join(agg_out_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gs, inp, outp in zip(gs_strs, inputs, outputs2):\n",
    "    print u'\"{}\"\\t\"{}\"\\t\"{}\"'.format(inp, gs, outp)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
