{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "#from codecs import open\n",
    "from lxml import etree\n",
    "\n",
    "from nlppln.utils import out_file_name, create_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from ochre.dbnl import Note, to_fragment, complete, get_repeated, extend_lines\n",
    "\n",
    "def remove_notes(ocr_file, notes_file, out_dir, pickle_dir=None):\n",
    "    with open(ocr_file) as f:\n",
    "        ls = f.readlines()\n",
    "\n",
    "    with open(notes_file) as f:\n",
    "        notes = f.readlines()\n",
    "        \n",
    "    print('There are {} notes to be found.'.format(len(notes)))\n",
    "        \n",
    "    # remove empty lines\n",
    "    lines = []\n",
    "\n",
    "    for line in ls:\n",
    "        if line.strip() != '':\n",
    "            lines.append(line)\n",
    "    print('The text contains {} lines.'.format(len(lines)))\n",
    "    \n",
    "    # get repeated notes\n",
    "    repeated = get_repeated(notes)\n",
    "    print('There are {} repeated notes.'.format(len(repeated)))\n",
    "    \n",
    "    pr = PartialRatio()\n",
    "    \n",
    "    print('Matching entire notes')\n",
    "\n",
    "    f = 0\n",
    "    fr = 0\n",
    "    prev_note = None\n",
    "    ns = []\n",
    "    text = ''.join(lines)\n",
    "    for i, n in enumerate(tqdm(notes)):\n",
    "        note = Note(n, i, len(lines))\n",
    "        score = pr.get_raw_score(note.text, text)\n",
    "        #print(i, 'score', score)\n",
    "        if score > 90:\n",
    "            note.found = True\n",
    "            f += 1\n",
    "        else:\n",
    "            note.found = False\n",
    "        if n in repeated:\n",
    "            note.repeated = True\n",
    "            if note.found:\n",
    "                fr += 1\n",
    "        else:\n",
    "            note.repeated = False\n",
    "        \n",
    "        note.previous = prev_note\n",
    "        prev_note = note\n",
    "    \n",
    "        ns.append(note)\n",
    "\n",
    "    ns.reverse()\n",
    "    for i, n in enumerate(ns):\n",
    "        if i > 0:\n",
    "            n.next = ns[i-1]\n",
    "    ns.reverse()\n",
    "    \n",
    "    print('Found {} notes.'.format(f))\n",
    "    print('Found and repeated: {} notes.'.format(fr))\n",
    "    fu = f - fr\n",
    "    \n",
    "    # roughly match found, unrepeated notes\n",
    "    print('Matching lines of found, unrepeated notes, pass 1')\n",
    "    pr = PartialRatio()\n",
    "    \n",
    "    scores = np.full((len(notes), len(lines)), np.inf)\n",
    "\n",
    "    f = 0\n",
    "    l = 0\n",
    "    for i, n in enumerate(tqdm(ns)):\n",
    "        #print(n)\n",
    "        #print(n.lines_to_check[:10])\n",
    "        #print('no of lines to check', len(n.lines_to_check))\n",
    "        if n.found and not n.repeated:\n",
    "            checked = 0\n",
    "            for idx in range(len(lines)):\n",
    "                if idx > n.get_search_start():\n",
    "                    checked += 1\n",
    "                    if scores[i, idx] == np.inf:\n",
    "                        scores[i, idx] = pr.get_raw_score(lines[idx], n.text)\n",
    "                        \n",
    "                    if scores[i, idx] > 90:\n",
    "                        l += 1\n",
    "                        n.lines.append(idx)\n",
    "                        break\n",
    "    print('Added {} lines.'.format(l))\n",
    "    if l != fu:\n",
    "        print('Did not add a line for all found unrepeated notes (found: {}, unreapeated: {}).'.format(l, fu))\n",
    "    else:\n",
    "        print('Added a line for all found unrepeated notes.')\n",
    "    print('Found {} \"complete\" notes.'.format(f))\n",
    "    \n",
    "    print('Matching lines of found, unrepeated notes, pass 2')\n",
    "    f = 0\n",
    "    l = 0\n",
    "    for i, n in enumerate(tqdm(ns)):\n",
    "        #print(n)\n",
    "        #print(n.lines_to_check[:10])\n",
    "        #print('no of lines to check', len(n.lines_to_check))\n",
    "        if n.found and not n.repeated:\n",
    "            checked = 0\n",
    "            for idx in range(len(lines)):\n",
    "                if idx in n.get_search_indices() and idx not in n.lines:\n",
    "                    checked += 1\n",
    "                    if scores[i, idx] == np.inf:\n",
    "                        scores[i, idx] = pr.get_raw_score(lines[idx], n.text)\n",
    "                        \n",
    "                    if scores[i, idx] > 90:\n",
    "                        l += 1\n",
    "                        n.lines.append(idx)\n",
    "                        if n.complete(lines):\n",
    "                            f += 1\n",
    "                            #print('Complete')\n",
    "                            #print(n.lines)\n",
    "                            #print(n.to_fragment(lines))\n",
    "                            #print('Checked:', checked)\n",
    "                            break\n",
    "            #print(n.lines)\n",
    "            #print('Checked:', checked)\n",
    "    print('Added {} lines.'.format(l))\n",
    "    print('Found {} \"complete\" notes.'.format(f))\n",
    "            \n",
    "    # roughly match unprepeated notes that didn't have an initial match\n",
    "    f = 0\n",
    "    l = 0\n",
    "    print('Matching lines of unfound, unrepeated notes')\n",
    "    for n in tqdm(ns):\n",
    "        #print(n)\n",
    "        #print(n.lines_to_check[:10])\n",
    "        #print('no of lines to check', len(n.lines_to_check))\n",
    "        if not n.found and not n.repeated:\n",
    "            checked = 0\n",
    "            for idx in n.get_search_indices():\n",
    "                checked += 1\n",
    "                score = pr.get_raw_score(lines[idx], n.text)\n",
    "                if score > 90:\n",
    "                    l += 1\n",
    "                    n.lines.append(idx)\n",
    "                    n.found = True\n",
    "                    if n.complete(lines):\n",
    "                        f += 1\n",
    "                        #print('Complete')\n",
    "                        #print(n.lines)\n",
    "                        #print(n.to_fragment(lines))\n",
    "                        #print('Checked:', checked)\n",
    "                        break\n",
    "            #print(n.lines)\n",
    "            #print('Checked:', checked)\n",
    "    \n",
    "    print('Added {} lines.'.format(l))\n",
    "    print('Found {} \"complete\" notes.'.format(f))\n",
    "            \n",
    "    # match repeated notes\n",
    "    f = 0\n",
    "    l = 0\n",
    "    print('Matching repeated notes')\n",
    "    for n in tqdm(ns):\n",
    "        #print(n)\n",
    "        #print(n.lines_to_check[:10])\n",
    "        #print('no of lines to check', len(n.lines_to_check))\n",
    "        if n.repeated:\n",
    "            checked = 0\n",
    "            for idx in n.get_search_indices():\n",
    "                checked += 1\n",
    "                score = pr.get_raw_score(lines[idx], n.text)\n",
    "                if score > 90:\n",
    "                    l += 1\n",
    "                    n.lines.append(idx)\n",
    "                    n.found = True\n",
    "                    if n.complete(lines):\n",
    "                        f += 1\n",
    "                        #print('Complete')\n",
    "                        #print(n.lines)\n",
    "                        #print(n.to_fragment(lines))\n",
    "                        #print('Checked:', checked)\n",
    "                        break\n",
    "            #print(n.lines)\n",
    "            #print('Checked:', checked)\n",
    "    \n",
    "    print('Added {} lines.'.format(l))\n",
    "    print('Found {} \"complete\" notes.'.format(f))\n",
    "        \n",
    "    print('Extending lines')\n",
    "    added = 0\n",
    "\n",
    "    for n in tqdm(ns):\n",
    "        #print(n)\n",
    "        #print(n.lines)\n",
    "        ls = copy.copy(n.lines)\n",
    "        extended = extend_lines(n.lines, len(lines), 5)\n",
    "        for idx in extended:\n",
    "            #print(idx)\n",
    "            if idx not in n.lines:\n",
    "                #print('Checking')\n",
    "                ed = n.ed(lines)\n",
    "                #print('ed', ed)\n",
    "                ls.append(idx)\n",
    "                ls.sort()\n",
    "                #print(ls)\n",
    "                new_ed = edlib.align(to_fragment(lines, ls), n.text)['editDistance']\n",
    "                #print('new_ed', new_ed)\n",
    "                if new_ed <= ed:\n",
    "                    #print('Adding', idx)\n",
    "                    added += 1\n",
    "                    n.lines.append(idx)\n",
    "                    n.lines.sort()\n",
    "                else:\n",
    "                    ls.remove(idx)\n",
    "        #print(n.lines)\n",
    "    print('Added {} lines.'.format(added))\n",
    "    \n",
    "    f = 0\n",
    "    c = 0\n",
    "    for n in ns:\n",
    "        if n.found:\n",
    "            f += 1\n",
    "        if n.complete(lines):\n",
    "            c += 1\n",
    "    print('Found {} of {} notes (complete: {})'.format(f, len(notes), c))\n",
    "    \n",
    "    if pickle_dir is not None:\n",
    "        out = out_file_name(pickle_dir, ocr_file)\n",
    "        print('Pickling to {}.'.format(out))\n",
    "        \n",
    "        create_dirs(out, is_file=True)\n",
    "        \n",
    "        with open(out, 'wb') as f:\n",
    "            pickle.dump(ns, f)\n",
    "\n",
    "    print('Removing notes')\n",
    "    removed = []\n",
    "\n",
    "    for n in ns:\n",
    "        for idx in n.lines:\n",
    "            removed.append(idx)\n",
    "            \n",
    "    # get the ocr text\n",
    "    with open(ocr_file) as f:\n",
    "        text = f.read()\n",
    "        \n",
    "    removed = list(set(removed))\n",
    "    for idx in removed:\n",
    "        l = lines[idx]\n",
    "        text = text.replace(l, '')\n",
    "\n",
    "    # save result\n",
    "    create_dirs(out_dir)\n",
    "    out = out_file_name(out_dir, ocr_file)\n",
    "    #print(out)\n",
    "    with open(out, 'w') as f:\n",
    "        f.write(text)\n",
    "        \n",
    "    return removed\n",
    "\n",
    "r = remove_notes('/home/jvdzwaan/data/dbnl_ocr/raw/ocr-with-title-page/_aio001jver01_01.txt', \n",
    "                 '/home/jvdzwaan/data/dbnl_ocr/raw/notes/_aio001jver01_01.txt',\n",
    "                 '/home/jvdzwaan/data/dbnl_ocr/raw/ocr',\n",
    "                 pickle_dir='/home/jvdzwaan/data/dbnl_ocr/raw/pickled')\n",
    "#print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from nlppln.utils import get_files, out_file_name, create_dirs\n",
    "\n",
    "in_dir = '/home/jvdzwaan/data/dbnl_ocr/raw/ocr-without-title-page/'\n",
    "notes_dir = '/home/jvdzwaan/data/dbnl_ocr/raw/notes/'\n",
    "out_dir = '/home/jvdzwaan/data/dbnl_ocr/raw/ocr-2passes'\n",
    "pickle_dir = '/home/jvdzwaan/data/dbnl_ocr/raw/pickled'\n",
    "\n",
    "create_dirs(out_dir)\n",
    "\n",
    "in_files = ['rade001gera01_01.txt', '_zev001198901_01.txt', '_tir001196201_01.txt',\n",
    "            'looy001wond03_01.txt', 'potg001jczi10_01.txt', 'berg050jaro01_01.txt',\n",
    "            '_tsj002195001_01.txt', '_jaa006199901_01.txt', '_taa006189101_01.txt',\n",
    "            '_sep001197201_01.txt', 'oltm003memo05_01.txt', '_noo001189201_01.txt',\n",
    "            'koni057heil01_01.txt', '_vla016197401_01.txt', '_bij005195501_01.txt']\n",
    "in_files = [os.path.join(in_dir, f) for f in in_files]\n",
    "\n",
    "with open('lines_removed_iteratively_2passes.txt', 'w') as f:\n",
    "    for in_file in tqdm(in_files):\n",
    "        out = out_file_name(out_dir, in_file)\n",
    "    \n",
    "        # is there a notes file?\n",
    "        notes_file = os.path.join(notes_dir, os.path.basename(in_file))\n",
    "        if os.path.isfile(notes_file):\n",
    "            print('processing', in_file)\n",
    "        \n",
    "            removed = remove_notes(in_file, notes_file, out_dir, pickle_dir=pickle_dir)\n",
    "            removed.sort()\n",
    "            f.write(os.path.basename(out))\n",
    "            f.write('\\t')\n",
    "            removed = [str(r) for r in removed]\n",
    "            f.write(','.join(removed))\n",
    "            f.write('\\n')\n",
    "        print('---')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
