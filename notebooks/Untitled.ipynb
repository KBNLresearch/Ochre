{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lees bestanden gt\n",
    "# connvert file names naar OCR\n",
    "# lees ocr bestanden\n",
    "import os\n",
    "\n",
    "from nlppln.utils import get_files\n",
    "\n",
    "gs_dir = '/home/jvdzwaan/ownCloud/Shared/OCR/Ground-truth/'\n",
    "ocr_dir = '/home/jvdzwaan/ownCloud/Shared/OCR/Originele ALTOs/'\n",
    "\n",
    "\n",
    "def gt_fname2ocr_fname(fname):\n",
    "    bn = os.path.basename(fname)\n",
    "    return bn.replace('GT', 'alto')\n",
    "\n",
    "gs_files = get_files(gs_dir)\n",
    "print(len(gs_files))\n",
    "print([f for f in gs_files if 'extra' in f])\n",
    "# remove file with \"extra\" in the name, this one is the same as the file without \"extra\" in the name\n",
    "gs_files = [f for f in gs_files if not 'extra' in f]\n",
    "print(len(gs_files))\n",
    "gt_fname2ocr_fname(gs_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_files = []\n",
    "for gs_file in gs_files:\n",
    "    ocr_bn = gt_fname2ocr_fname(gs_file)\n",
    "    ocr_file = os.path.join(ocr_dir, ocr_bn)\n",
    "    if os.path.isfile(ocr_file):\n",
    "        ocr_files.append(ocr_file)\n",
    "    else:\n",
    "        print('File not found:', ocr_file)\n",
    "        print('GS file:', gs_file)\n",
    "print(len(ocr_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "from lxml import etree\n",
    "\n",
    "def get_words_in_textlines(fname, alto_ns):\n",
    "    lines = OrderedDict()\n",
    "    context = etree.iterparse(fname, events=('end', ), tag=(alto_ns+'TextLine'))\n",
    "    for event, elem in context:\n",
    "        lines[elem.attrib['ID']] = []\n",
    "        for a in elem.getchildren():\n",
    "            if a.tag == alto_ns+'String':\n",
    "                if a.attrib.get('SUBS_TYPE') == 'HypPart1':\n",
    "                    lines[elem.attrib['ID']].append(a.attrib['SUBS_CONTENT'])\n",
    "                elif a.attrib.get('SUBS_TYPE') != 'HypPart2':\n",
    "                    lines[elem.attrib['ID']].append(a.attrib['CONTENT'])\n",
    "                    \n",
    "        #for a in elem.getchildren():\n",
    "        #    if a.tag == alto_ns+'String':\n",
    "        #        lines[elem.attrib['ID']].append(a.attrib['CONTENT'])\n",
    "        \n",
    "         # make iteration over context fast and consume less memory\n",
    "        #https://www.ibm.com/developerworks/xml/library/x-hiperfparse\n",
    "        elem.clear()\n",
    "        while elem.getprevious() is not None:\n",
    "            del elem.getparent()[0]\n",
    "            \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
