{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let op**: De orginele alto's en nieuwe ground truth gebruiken andere namepaces voor de alto tags:\n",
    "\n",
    "* OCR: http://schema.ccs-gmbh.com/ALTO, heeft meerdere alternatieven\n",
    "* GT: http://www.loc.gov/standards/alto/ns-v2#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lees bestanden gt\n",
    "# connvert file names naar OCR\n",
    "# lees ocr bestanden\n",
    "import os\n",
    "\n",
    "from nlppln.utils import get_files\n",
    "\n",
    "gs_dir = '/home/jvdzwaan/ownCloud/Shared/OCR/Ground-truth/'\n",
    "ocr_dir = '/home/jvdzwaan/ownCloud/Shared/OCR/Originele ALTOs/'\n",
    "\n",
    "\n",
    "def gt_fname2ocr_fname(fname):\n",
    "    bn = os.path.basename(fname)\n",
    "    return bn.replace('GT', 'alto')\n",
    "\n",
    "gs_files = get_files(gs_dir)\n",
    "print(len(gs_files))\n",
    "print([f for f in gs_files if 'extra' in f])\n",
    "# remove file with \"extra\" in the name, this one is the same as the file without \"extra\" in the name\n",
    "gs_files = [f for f in gs_files if not 'extra' in f]\n",
    "print(len(gs_files))\n",
    "gt_fname2ocr_fname(gs_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_files = []\n",
    "for gs_file in gs_files:\n",
    "    ocr_bn = gt_fname2ocr_fname(gs_file)\n",
    "    ocr_file = os.path.join(ocr_dir, ocr_bn)\n",
    "    if os.path.isfile(ocr_file):\n",
    "        ocr_files.append(ocr_file)\n",
    "    else:\n",
    "        print('File not found:', ocr_file)\n",
    "        print('GS file:', gs_file)\n",
    "print(len(ocr_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "from lxml import etree\n",
    "\n",
    "def get_words_in_textlines(fname, alto_ns):\n",
    "    lines = OrderedDict()\n",
    "    context = etree.iterparse(fname, events=('end', ), tag=(alto_ns+'TextLine'))\n",
    "    for event, elem in context:\n",
    "        lines[elem.attrib['ID']] = []\n",
    "        for a in elem.getchildren():\n",
    "            if a.tag == alto_ns+'String':\n",
    "                if a.attrib.get('SUBS_TYPE') == 'HypPart1':\n",
    "                    lines[elem.attrib['ID']].append(a.attrib['SUBS_CONTENT'])\n",
    "                elif a.attrib.get('SUBS_TYPE') != 'HypPart2':\n",
    "                    lines[elem.attrib['ID']].append(a.attrib['CONTENT'])\n",
    "                    \n",
    "        #for a in elem.getchildren():\n",
    "        #    if a.tag == alto_ns+'String':\n",
    "        #        lines[elem.attrib['ID']].append(a.attrib['CONTENT'])\n",
    "        \n",
    "         # make iteration over context fast and consume less memory\n",
    "        #https://www.ibm.com/developerworks/xml/library/x-hiperfparse\n",
    "        elem.clear()\n",
    "        while elem.getprevious() is not None:\n",
    "            del elem.getparent()[0]\n",
    "            \n",
    "    return lines\n",
    "\n",
    "#get_words_in_textlines('/home/jvdzwaan/ownCloud/Shared/OCR/Originele ALTOs/DDD_000010534_002_alto.xml', \n",
    "#             alto_ns='{http://schema.ccs-gmbh.com/ALTO}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ochre.matchlines import get_ns\n",
    "\n",
    "ns = get_ns(gs_files[0])\n",
    "gs_lines = get_words_in_textlines(gs_files[1], ns)\n",
    "ns = get_ns(ocr_files[0])\n",
    "ocr_lines = get_words_in_textlines(ocr_files[1], ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edlib\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from ochre.matchlines import Match, count_unknown\n",
    "\n",
    "def initialize_matches(gs_lines, ocr_lines):\n",
    "    #print(gs_lines.keys())\n",
    "\n",
    "    matches = [Match(label, i) for i, label in enumerate(gs_lines.keys())]\n",
    "    \n",
    "    #print('End phase 1')\n",
    "    \n",
    "    for i, m in enumerate(matches):\n",
    "        #print('set edit distances')\n",
    "        # set edit distances\n",
    "        gs = ' '.join(gs_lines[m.gs_label])\n",
    "        #print(gs, m.gs_label)\n",
    "    \n",
    "        to_check = list(ocr_lines.keys())[max(0, i-50):i+50]\n",
    "    \n",
    "        eds = OrderedDict()\n",
    "        for ocr_id in to_check:\n",
    "            ocr = ' '.join(ocr_lines[ocr_id])\n",
    "            \n",
    "            #print(len(gs), len(ocr))\n",
    "            #print(len(gs.strip()), len(ocr.strip()))\n",
    "            \n",
    "            if len(gs) != 0 and len(ocr) != 0:\n",
    "                #print(repr(gs))\n",
    "                #print(repr(ocr))\n",
    "                #print('calculating edit distance')\n",
    "            \n",
    "                r = edlib.align(gs, ocr)\n",
    "                eds[ocr_id] = r['editDistance']\n",
    "            else: \n",
    "                #print('FOuns zroe')\n",
    "                if len(gs) == 0:\n",
    "                    eds[ocr_id] = len(ocr)\n",
    "                elif len(ocr) == 0:\n",
    "                    eds[ocr_id] = len(gs)\n",
    "                #print(repr(gs))\n",
    "                #print(repr(ocr))\n",
    "        \n",
    "        m.eds = eds\n",
    "        \n",
    "        #print('set preb and next')\n",
    "        \n",
    "        # Set previous and next\n",
    "        if i > 0:\n",
    "            m.previous = matches[i-1]\n",
    "            #print('previous', m.previous)\n",
    "        if i < len(matches)-1:\n",
    "            m.next = matches[i+1]\n",
    "            \n",
    "    #print('End initialize')\n",
    "    \n",
    "    return matches\n",
    "\n",
    "\n",
    "def set_zero(matches, used):\n",
    "    for i, m in enumerate(matches):\n",
    "        if min(m.eds.values()) == 0:\n",
    "            ocr_label = list(m.eds.keys())[list(m.eds.values()).index(0)]\n",
    "            used.append(ocr_label)\n",
    "            #print(ocr_label)\n",
    "                        \n",
    "            m.ocr_label = ocr_label\n",
    "        #print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = initialize_matches(gs_lines, ocr_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ochre.matchlines import UNKNOWN, EMPTY\n",
    "\n",
    "def match_close(matches, ocr_lines, used):\n",
    "\n",
    "    for m in matches:\n",
    "        if m.ocr_label == UNKNOWN:\n",
    "            #print(m)\n",
    "            ocr_label = m.get_match(ocr_lines, matches, used, method='close')\n",
    "            m.ocr_label = ocr_label\n",
    "            if ocr_label != UNKNOWN and ocr_label != EMPTY:\n",
    "                used.append(ocr_label)\n",
    "            #print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ochre.matchlines import print_match\n",
    "\n",
    "for m in matches:\n",
    "    print(print_match(m, gs_lines, ocr_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = matches[259]\n",
    "#print(m)\n",
    "print(print_match(m, gs_lines, ocr_lines))\n",
    "#print(m.get_options(ocr_lines, used))\n",
    "lbl = m.get_match(ocr_lines, matches, used, method='best')\n",
    "print(' '.join(ocr_lines['P2_TL00260']))\n",
    "lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaps(matches):\n",
    "    unknowns = []\n",
    "    gs_labels = []\n",
    "    unk = False\n",
    "\n",
    "    for m in matches:\n",
    "        if m.ocr_label == UNKNOWN:\n",
    "            unk = True\n",
    "            unknowns.append(m)\n",
    "            gs_labels.append(m.gs_label)\n",
    "        elif unk:\n",
    "            yield unknowns, gs_labels\n",
    "            unk = False\n",
    "            unknowns = []\n",
    "            gs_labels = []\n",
    "\n",
    "def match_gaps(matches, used, ocr_lines):\n",
    "    for unknowns, gs_labels in gaps(matches):\n",
    "        if len(unknowns) > 0:\n",
    "            #print(len(gs_labels), len(unknowns))\n",
    "    \n",
    "            if len(unknowns) > 0 and len(unknowns) == len(gs_labels):\n",
    "                if unknowns[0].previous is not None:\n",
    "                    start_index = list(ocr_lines.keys()).index(unknowns[0].previous.ocr_label) + 1\n",
    "                else: \n",
    "                    start_index = 0\n",
    "                    \n",
    "                if unknowns[-1].next is not None:\n",
    "                    stop_index = list(ocr_lines.keys()).index(unknowns[-1].next.ocr_label)\n",
    "                else:\n",
    "                    stop_index = list(ocr_lines.keys())[-1]\n",
    "                #print(start_index, stop_index)\n",
    "                #print([i for i in range(start_index, stop_index)])\n",
    "                options = [list(ocr_lines.keys())[i] for i in range(start_index, stop_index)]\n",
    "                p_options = []\n",
    "                for u in unknowns:\n",
    "                    for o in u.get_options(ocr_lines, used).keys():\n",
    "                        if o not in p_options:\n",
    "                            p_options.append(o)\n",
    "                #print('possible options', p_options)\n",
    "                if len(p_options) == len(gs_labels):\n",
    "                #    print(options)\n",
    "                #    print(set(options).intersection(set(used)))\n",
    "                #    if len(set(options).intersection(set(used))) == 0:\n",
    "                     for m, ocr_label in zip(unknowns, p_options):\n",
    "                            #print(m)\n",
    "                            #print(list(ocr_lines.keys())[i])\n",
    "                            m.ocr_label = ocr_label\n",
    "                            used.append(ocr_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_match_best(matches, used, ocr_lines):\n",
    "    prev_unknown = len(matches)\n",
    "    num_unknown = count_unknown(matches)\n",
    "    \n",
    "    while num_unknown < prev_unknown:\n",
    "        for m in matches:\n",
    "            if m.ocr_label == UNKNOWN:\n",
    "                #print(m)\n",
    "                ocr_label = m.get_match(ocr_lines, matches, used, method='best')\n",
    "                m.ocr_label = ocr_label\n",
    "                if ocr_label != UNKNOWN and ocr_label != EMPTY:\n",
    "                    used.append(ocr_label)\n",
    "                #print(m)\n",
    "        prev_unknown = num_unknown\n",
    "        num_unknown = count_unknown(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def edlib2pair(query: str, ref: str, mode: str = \"NW\") -> str:\n",
    "    \"\"\"\n",
    "    input:\n",
    "    query and ref sequence\n",
    "\n",
    "    output:\n",
    "    TAAGGATGGTCCCAT TC\n",
    "     ||||  ||||.||| ||\n",
    "     AAGG  GGTCTCATATC\n",
    "    \"\"\"\n",
    "\n",
    "    a = edlib.align(query, ref, mode=mode, task=\"path\")\n",
    "    ref_pos = a[\"locations\"][0][0]\n",
    "    query_pos = 0\n",
    "    ref_aln = []\n",
    "    match_aln = \"\"\n",
    "    query_aln = []\n",
    "\n",
    "    for step, code in re.findall(r\"(\\d+)(\\D)\", a[\"cigar\"]):\n",
    "        step = int(step)\n",
    "        if code == \"=\":\n",
    "            for c in ref[ref_pos : ref_pos + step]:\n",
    "                ref_aln.append(c)\n",
    "            #ref_aln += ref[ref_pos : ref_pos + step]\n",
    "            ref_pos += step\n",
    "            for c in query[query_pos : query_pos + step]:\n",
    "                query_aln.append(c)\n",
    "            #query_aln += query[query_pos : query_pos + step]\n",
    "            query_pos += step\n",
    "            match_aln += \"|\" * step\n",
    "        elif code == \"X\":\n",
    "            for c in ref[ref_pos : ref_pos + step]:\n",
    "                ref_aln.append(c)\n",
    "            #ref_aln += ref[ref_pos : ref_pos + step]\n",
    "            ref_pos += step\n",
    "            for c in query[query_pos : query_pos + step]:\n",
    "                query_aln.append(c)\n",
    "            #query_aln += query[query_pos : query_pos + step]\n",
    "            query_pos += step\n",
    "            match_aln += \".\" * step\n",
    "        elif code == \"D\":\n",
    "            for c in ref[ref_pos : ref_pos + step]:\n",
    "                ref_aln.append(c)\n",
    "            #ref_aln += ref[ref_pos : ref_pos + step]\n",
    "            ref_pos += step\n",
    "            #query_aln += \" \" * step\n",
    "            query_pos += 0\n",
    "            for i in range(step):\n",
    "                query_aln.append('')\n",
    "            match_aln += \" \" * step\n",
    "        elif code == \"I\":\n",
    "            for i in range(step):\n",
    "                ref_aln.append('')\n",
    "            #ref_aln += \" \" * step\n",
    "            ref_pos += 0\n",
    "            for c in query[query_pos : query_pos + step]:\n",
    "                query_aln.append(c)\n",
    "            #query_aln += query[query_pos : query_pos + step]\n",
    "            query_pos += step\n",
    "            match_aln += \" \" * step\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return ref_aln, match_aln, query_aln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edlib\n",
    "import json\n",
    "\n",
    "from nlppln.utils import create_dirs, out_file_name\n",
    "from ochre.utils import align_characters\n",
    "\n",
    "def align_page(matches):\n",
    "    ocr_result = []\n",
    "    gs_result = []\n",
    "\n",
    "    for m in matches:\n",
    "        gs = ' '.join(gs_lines[m.gs_label])\n",
    "        ocr = ' '.join(ocr_lines.get(m.ocr_label, ''))\n",
    "    \n",
    "        #print(' GS:', repr(gs))\n",
    "        #print('OCR:', repr(ocr))\n",
    "        #print(len(gs), len(ocr))\n",
    "    \n",
    "        gs_a, match_a, ocr_a = edlib2pair(gs, ocr, mode='NW')\n",
    "        if len(ocr_a) != len(gs_a):\n",
    "            print('UNEQUAL!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        \n",
    "        for o, g in zip(ocr_a, gs_a):\n",
    "            ocr_result.append(o)\n",
    "            gs_result.append(g)\n",
    "        #    print(o,g)\n",
    "        #print('---')\n",
    "    return gs_result, ocr_result\n",
    "\n",
    "def doc_id(fname):\n",
    "    bn = os.path.basename(fname)\n",
    "    n = bn.rsplit('_', 1)[0]\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ochre.matchlines import get_ns, replace_entities\n",
    "from ochre.utils import get_temp_file\n",
    "\n",
    "from nlppln.utils import create_dirs, out_file_name\n",
    "\n",
    "def do_matching(gs_lines, ocr_lines):\n",
    "    print('Number of lines in gs', len(gs_lines))\n",
    "    print('Number of lines in ocr', len(ocr_lines))\n",
    "\n",
    "    matches = initialize_matches(gs_lines, ocr_lines)\n",
    "    \n",
    "    #matches = []\n",
    "    \n",
    "    used = []\n",
    "    set_zero(matches, used)\n",
    "    \n",
    "    num_unknown = count_unknown(matches)\n",
    "    print('Unknown after set zero:', num_unknown)\n",
    "    \n",
    "    match_close(matches, ocr_lines, used)\n",
    "    \n",
    "    num_unknown = count_unknown(matches)\n",
    "    print('Unknown after match close:', num_unknown)\n",
    "    \n",
    "    match_gaps(matches, used, ocr_lines)\n",
    "    \n",
    "    num_unknown = count_unknown(matches)\n",
    "    print('Unknown after match gaps:', num_unknown)\n",
    "    \n",
    "    repeat_match_best(matches, used, ocr_lines)\n",
    "    \n",
    "    num_unknown = count_unknown(matches)\n",
    "    print('Unknown after match gaps:', num_unknown)\n",
    "    \n",
    "    return matches\n",
    "\n",
    "\n",
    "out_dir = '/home/jvdzwaan/data/kb-ocr/text-not-aligned/aligned'\n",
    "create_dirs(out_dir)\n",
    "\n",
    "for gs_file, ocr_file in tqdm(zip(gs_files, ocr_files), total=len(gs_files)):\n",
    "    print(gs_file)\n",
    "    print(ocr_file)\n",
    "    \n",
    "    gs_tmp = get_temp_file()\n",
    "    #print(gs_tmp)\n",
    "    with open(gs_tmp, 'w') as f:\n",
    "        f.write(replace_entities(gs_file))\n",
    "            \n",
    "    #ocr_tmp = get_temp_file()\n",
    "    #print(gs_tmp)\n",
    "    #with open(ocr_tmp, 'w') as f:\n",
    "    #    f.write(replace_entities(ocr_file))\n",
    "        \n",
    "    gs_lines = get_words_in_textlines(gs_tmp, get_ns(gs_file))\n",
    "    ocr_lines = get_words_in_textlines(ocr_file, get_ns(ocr_file))\n",
    "    print(len(gs_lines), len(ocr_lines))\n",
    "    \n",
    "    os.remove(gs_tmp)\n",
    "    \n",
    "    matches = do_matching(gs_lines, ocr_lines)\n",
    "    \n",
    "    #gs_a, ocr_a = align_page(matches)\n",
    "    #out_file = out_file_name(out_dir, doc_id(gs_file), 'json')\n",
    "    #print('Writing', out_file)\n",
    "    #with open(out_file, 'w') as f:\n",
    "    #    json.dump({'ocr': ocr_a, 'gs': gs_a}, f)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
