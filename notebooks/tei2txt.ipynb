{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lxml import etree\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "from nlppln.utils import get_files\n",
    "\n",
    "in_files = get_files('/home/jvdzwaan/Downloads/dbnl_ocr/xml/')\n",
    "print(len(in_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from codecs import open\n",
    "from lxml import etree\n",
    "\n",
    "from nlppln.utils import out_file_name, create_dirs\n",
    "\n",
    "def replace_entities(fname, out_dir):\n",
    "    with open(fname, encoding='utf8') as f:\n",
    "        text = f.read()\n",
    "    text = text.replace('&nbsp;', '&#160;')\n",
    "    text = text.replace('&ldquo;', '&#8220;')\n",
    "    text = text.replace('&rdquo;', '&#8221;')\n",
    "    text = text.replace('&lsquo;', '&#8216;')   # left single quote\n",
    "    text = text.replace('&rsquo;', '&#8217;')   # right single quote\n",
    "    text = text.replace('&copy;', '&#169;')\n",
    "    text = text.replace('&fnof;', '&#192;')     # f-sign (guilders)\n",
    "    text = text.replace('&rarr;', '&#8594;')    # rightwards arrow\n",
    "    text = text.replace('&Euml;', '&#203;')     # capital E, dieresis or umlaut mark\n",
    "    text = text.replace('&Uuml;', '&#220;')     # capital U, dieresis or umlaut mark\n",
    "    text = text.replace('&Auml;', '&#196;')     # capital A, dieresis or umlaut mark\n",
    "    text = text.replace('&Ouml;', '&#214;')     # capital O, dieresis or umlaut mark\n",
    "    text = text.replace('&Egrave;', '&#353;')     # capital E, grave accent\n",
    "    text = text.replace('&scaron;', '&#200;')     # latin small letter s with caron\n",
    "    text = text.replace('&yacute;', '&#253;')     # y, acute accent\n",
    "    text = text.replace('&otilde;', '&#245;')   # small o, tilde\n",
    "    text = text.replace('&atilde;', '&#227;')   # small a, tilde\n",
    "    text = text.replace('&ntilde;', '&#241;')   # small n, tilde\n",
    "    text = text.replace('&plusmn;', '&#177;')   # +/-\n",
    "    text = text.replace('&times;', '&#215;')    # multiply sign\n",
    "    text = text.replace('&sect;', '&#167;')    # section (?)\n",
    "    text = text.replace('&pi;', '&#960;')    # pi\n",
    "    text = text.replace('&Epsilon;', '&#917;')    # greek capital letter epsilon\n",
    "    text = text.replace('&rho;', '&#961;')    # greek small letter rho\n",
    "    text = text.replace('&omega;', '&#969;')    # greek small letter omega\n",
    "    text = text.replace('&tau;', '&#964;')    # greek small letter tau\n",
    "    text = text.replace('&omicron;', '&#959;')    # greek small letter omicron\n",
    "    text = text.replace('&alpha;', '&#945;')    # greek small letter alpha\n",
    "    text = text.replace('&iota;', '&#953;')    # greek small letter iota\n",
    "    text = text.replace('&gamma;', '&#947;')    # greek small letter gamma\n",
    "    text = text.replace('&nu;', '&#957;')    # greek small letter nu\n",
    "    text = text.replace('&sigmaf;', '&#962;')    # greek small letter final sigma\n",
    "    text = text.replace('&upsilon;', '&#965;')    # greek small letter upsilon\n",
    "    text = text.replace('&kappa;', '&#954;')    # greek small letter kappa\n",
    "    text = text.replace('&mu;', '&#956;')    # greek small letter mu\n",
    "    text = text.replace('&lambda;', '&#955;')    # greek small letter lambda\n",
    "    text = text.replace('&epsilon;', '&#949;')    # greek small letter epsilon\n",
    "    text = text.replace('&eta;', '&#951;')    # greek small letter eta\n",
    "    text = text.replace('&delta;', '&#948;')    # greek small letter delta\n",
    "    text = text.replace('&theta;', '&#952;')    # greek small letter theta\n",
    "    text = text.replace('&phi;', '&#966;')    # greek small letter phi\n",
    "    text = text.replace('&zeta;', '&#950;')    # greek small letter zeta\n",
    "    text = text.replace('&sigma;', '&#963;')    # greek small letter sigma\n",
    "    text = text.replace('&beta;', '&#946;')    # greek small letter beta\n",
    "    text = text.replace('&chi;', '&#967;')    # greek small letter chi\n",
    "    text = text.replace('&Tau;', '&#932;')    # greek capital letter tau\n",
    "    text = text.replace('&Mu;', '&#924;')    # greek capital letter mu\n",
    "    text = text.replace('&Eta;', '&#919;')    # greek capital letter eta\n",
    "    text = text.replace('&Omicron;', '&#927;')    # greek capital letter omicron\n",
    "    text = text.replace('&Delta;', '&#916;')    # greek small letter delta\n",
    "    \n",
    "     \n",
    "    out_file = out_file_name(out_dir, fname)\n",
    "    #print(out_file)\n",
    "    with open(out_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(text)\n",
    "    \n",
    "    # Test whether result is valid xml\n",
    "    #root = etree.parse(out_file)\n",
    "\n",
    "out_dir = '/home/jvdzwaan/data/dbnl_ocr/raw/xml-without-entities/'\n",
    "create_dirs(out_dir)\n",
    "#for in_file in tqdm(['/home/jvdzwaan/data/dbnl_ocr/raw/xml-without-entities/ypes001petr01_01.xml']):\n",
    "for in_file in tqdm(in_files):\n",
    "    replace_entities(in_file, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# remove empty files\n",
    "in_dir = '/home/jvdzwaan/data/dbnl_ocr/raw/xml-without-entities/'\n",
    "!python -m nlppln.commands.delete_empty_files {in_dir} -o {in_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/home/jvdzwaan/data/dbnl_ocr/raw/xml-without-entities/'\n",
    "in_files = get_files(out_dir)\n",
    "print(len(in_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(in_files[35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# extract notes from xml\n",
    "# save notes to file (one note per line)\n",
    "# TOO SLOW\n",
    "\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from codecs import open\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from nlppln.utils import out_file_name, create_dirs\n",
    "\n",
    "def extract_notes(in_file, out_dir, notes_dir):\n",
    "    with open(in_file) as f:\n",
    "        soup = BeautifulSoup(f, 'xml')\n",
    "    \n",
    "    num_notes = 0\n",
    "    notes_file = out_file_name(notes_dir, in_file, ext='txt')\n",
    "    \n",
    "    with open(notes_file, 'w', encoding='utf-8') as f:\n",
    "    \n",
    "        notes = soup.find_all('note')\n",
    "        for note in notes:\n",
    "            n = note.extract()\n",
    "            txt = n.get_text()\n",
    "            if len(txt) > 0:\n",
    "                num_notes += 1\n",
    "                f.write(txt)\n",
    "                f.write('\\n')\n",
    "                \n",
    "    #print('num_notes:', num_notes)\n",
    "                \n",
    "    heads = soup.find_all('head')\n",
    "    for head in heads:\n",
    "        m = re.match(r'\\[.+\\]', head.get_text())\n",
    "        if m:\n",
    "            head.extract()\n",
    "\n",
    "    out_file = out_file_name(out_dir, in_file)\n",
    "    with open(out_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(soup.prettify())\n",
    "    \n",
    "out_dir = '/home/jvdzwaan/data/dbnl_ocr/raw/xml-without-notes-and-headers/'\n",
    "notes_dir = '/home/jvdzwaan/data/dbnl_ocr/raw/notes/'\n",
    "\n",
    "create_dirs(out_dir)\n",
    "create_dirs(notes_dir)\n",
    "\n",
    "#for in_file in ('/home/jvdzwaan/data/dbnl_ocr/raw/xml-without-entities/_aio001jver01_01.xml', ):\n",
    "for in_file in tqdm(in_files):\n",
    "    extract_notes(in_file, out_dir, notes_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from lxml import etree\n",
    "\n",
    "from nlppln.utils import out_file_name, create_dirs\n",
    "\n",
    "def process_xml(fname, out_dir, notes_dir):\n",
    "    root = etree.parse(fname)\n",
    "    #root = tree.getroot()\n",
    "    #print(root.tag)\n",
    "    #print(root.getroot().tag)\n",
    "    \n",
    "    notes = root.iter('note')\n",
    "    notes_text = []\n",
    "    num_notes = 0\n",
    "    \n",
    "    \n",
    "    for note in notes:\n",
    "        #print(note.getparent())\n",
    "        parent = note.getparent()\n",
    "        if parent.tag != 'notesStmt':\n",
    "            num_notes += 1\n",
    "            txt = ''.join(note.itertext())\n",
    "            #print(txt)\n",
    "            if len(txt.strip()) > 0:\n",
    "                notes_text.append(txt.replace('\\n', ' '))\n",
    "    #print('num_notes:', num_notes)\n",
    "    \n",
    "    # because of nested notes, we need to iterate again for removing notes\n",
    "    # we also need to reverse the notes list, to remove the nested notes before their parents\n",
    "    # otherwise some notes will be left\n",
    "    notes = [n for n in root.iter('note')]\n",
    "    notes.reverse()\n",
    "    for note in notes:\n",
    "        note.getparent().remove(note)\n",
    "    \n",
    "    #print(len(notes_text))\n",
    "    if len(notes_text) > 0:\n",
    "        notes_file = out_file_name(notes_dir, in_file, ext='txt')\n",
    "        with open(notes_file, 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(notes_text))\n",
    "\n",
    "    heads = root.iter('head')\n",
    "    for head in heads:\n",
    "        #print(head.text)\n",
    "        m = re.match(r'\\[.+\\]', ''.join(head.itertext()))\n",
    "        if m:\n",
    "            #print('deleting')\n",
    "            head.getparent().remove(head)\n",
    "            \n",
    "    out_file = out_file_name(out_dir, in_file)\n",
    "    #print(out_file)\n",
    "    with open(out_file, 'wb') as f:\n",
    "        f.write(etree.tostring(root, pretty_print=True, encoding='utf-8'))\n",
    "\n",
    "\n",
    "out_dir = '/home/jvdzwaan/data/dbnl_ocr/raw/xml-without-notes-and-headers/'\n",
    "notes_dir = '/home/jvdzwaan/data/dbnl_ocr/raw/notes/'\n",
    "\n",
    "create_dirs(out_dir)\n",
    "create_dirs(notes_dir)\n",
    "\n",
    "#for in_file in ('/home/jvdzwaan/data/dbnl_ocr/raw/xml-without-entities/_aio001jver01_01.xml', ):\n",
    "for in_file in tqdm(in_files):\n",
    "    process_xml(in_file, out_dir, notes_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = out_dir\n",
    "\n",
    "in_files = get_files(in_dir)\n",
    "print(len(in_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from nlppln.utils import create_dirs, out_file_name\n",
    "\n",
    "def tei2txt(fname):\n",
    "    root = etree.parse(fname)\n",
    "    body = root.find('text').find('body')\n",
    "    #print(body)\n",
    "    txt = ''.join(body.itertext())\n",
    "    return txt\n",
    "\n",
    "in_dir = '/home/jvdzwaan/data/dbnl_ocr/raw/xml-without-notes-and-headers/'\n",
    "out_dir = '/home/jvdzwaan/data/dbnl_ocr/raw/gs-unfiltered'\n",
    "\n",
    "create_dirs(out_dir)\n",
    "\n",
    "in_files = get_files(in_dir)\n",
    "\n",
    "for in_file in tqdm(in_files):\n",
    "    txt = tei2txt(in_file)\n",
    "    out_file = out_file_name(fname=in_file, out_dir=out_dir, ext='txt')\n",
    "    print(out_file)\n",
    "    with open(out_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(txt)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
