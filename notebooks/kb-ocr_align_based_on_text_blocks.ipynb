{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "from lxml import etree\n",
    "\n",
    "from ochre.matchlines import get_ns\n",
    "\n",
    "def get_textblocks_lines(fname):\n",
    "    alto_ns = get_ns(fname)\n",
    "    blocks = {}\n",
    "    \n",
    "    num_blocks = 0\n",
    "    \n",
    "    context = etree.iterparse(fname, events=('end', ), tag=(alto_ns+'TextBlock'))\n",
    "    for event, elem in context:\n",
    "        blocks[elem.attrib['ID']] = OrderedDict()\n",
    "        num_blocks += 1\n",
    "        for a in elem.getchildren():\n",
    "            if a.tag == alto_ns+'TextLine':\n",
    "                blocks[elem.attrib['ID']][a.attrib['ID']] = []\n",
    "                for b in a.getchildren():\n",
    "                    if b.tag == alto_ns+'String':\n",
    "                        if b.attrib.get('SUBS_TYPE') == 'HypPart1':\n",
    "                            blocks[elem.attrib['ID']][a.attrib['ID']].append(b.attrib['SUBS_CONTENT'])\n",
    "                        elif b.attrib.get('SUBS_TYPE') != 'HypPart2':\n",
    "                            blocks[elem.attrib['ID']][a.attrib['ID']].append(b.attrib['CONTENT'])\n",
    "                    \n",
    "        #for a in elem.getchildren():\n",
    "        #    if a.tag == alto_ns+'String':\n",
    "        #        lines[elem.attrib['ID']].append(a.attrib['CONTENT'])\n",
    "        \n",
    "         # make iteration over context fast and consume less memory\n",
    "        #https://www.ibm.com/developerworks/xml/library/x-hiperfparse\n",
    "        elem.clear()\n",
    "        while elem.getprevious() is not None:\n",
    "            del elem.getparent()[0]\n",
    "            \n",
    "    return blocks\n",
    "\n",
    "# blocks equal length\n",
    "in_file_ocr = '/home/jvdzwaan/ownCloud/Shared/OCR/Originele ALTOs/DDD_010017911_002_alto.xml'\n",
    "in_file_gt = '/home/jvdzwaan/ownCloud/Shared/OCR/Ground-truth/DDD_010017911_002_GT.xml'\n",
    "\n",
    "# blocks not equal length\n",
    "#in_file_ocr = '/home/jvdzwaan/ownCloud/Shared/OCR/Originele ALTOs/DDD_010007697_002_alto.xml'\n",
    "#in_file_gt = '/home/jvdzwaan/ownCloud/Shared/OCR/Ground-truth/DDD_010007697_002_GT.xml'\n",
    "\n",
    "\n",
    "blocks_gs = get_textblocks_lines(in_file_gt)\n",
    "blocks_ocr = get_textblocks_lines(in_file_ocr)\n",
    "\n",
    "print(len(blocks_gs), len(blocks_ocr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edlib\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from ochre.matchlines import Match, count_unknown\n",
    "\n",
    "def initialize_matches(gs_lines, ocr_lines):\n",
    "    #print(gs_lines.keys())\n",
    "\n",
    "    matches = [Match(label, i) for i, label in enumerate(gs_lines.keys())]\n",
    "    \n",
    "    #print('End phase 1')\n",
    "    \n",
    "    for i, m in enumerate(matches):\n",
    "        #print('set edit distances', i)\n",
    "        # set edit distances\n",
    "        gs = ' '.join(gs_lines[m.gs_label])\n",
    "        #print(gs, m.gs_label)\n",
    "    \n",
    "        to_check = list(ocr_lines.keys())[max(0, i-50):i+50]\n",
    "        #print('to_check', to_check)\n",
    "    \n",
    "        eds = OrderedDict()\n",
    "        for ocr_id in to_check:\n",
    "            ocr = ' '.join(ocr_lines[ocr_id])\n",
    "            \n",
    "            #print(len(gs), len(ocr))\n",
    "            #print(len(gs.strip()), len(ocr.strip()))\n",
    "            \n",
    "            if len(gs) != 0 and len(ocr) != 0:\n",
    "                #print(repr(gs))\n",
    "                #print(repr(ocr))\n",
    "                #print('calculating edit distance')\n",
    "            \n",
    "                r = edlib.align(gs, ocr)\n",
    "                eds[ocr_id] = r['editDistance']\n",
    "            else: \n",
    "                #print('FOuns zroe')\n",
    "                if len(gs) == 0:\n",
    "                    eds[ocr_id] = len(ocr)\n",
    "                elif len(ocr) == 0:\n",
    "                    eds[ocr_id] = len(gs)\n",
    "                #print(repr(gs))\n",
    "                #print(repr(ocr))\n",
    "                \n",
    "        #print(eds)\n",
    "        \n",
    "        m.eds = eds\n",
    "        \n",
    "        #print('set preb and next')\n",
    "        \n",
    "        # Set previous and next\n",
    "        if i > 0:\n",
    "            m.previous = matches[i-1]\n",
    "            #print('previous', m.previous)\n",
    "        if i < len(matches)-1:\n",
    "            m.next = matches[i+1]\n",
    "            \n",
    "    #print('End initialize')\n",
    "    \n",
    "    return matches\n",
    "\n",
    "\n",
    "def set_zero(matches, used):\n",
    "    #print('Set zero', len(matches))\n",
    "    for i, m in enumerate(matches):\n",
    "        #print(m)\n",
    "        if len(m.eds) > 0:\n",
    "            if min(m.eds.values()) == 0:\n",
    "                ocr_label = list(m.eds.keys())[list(m.eds.values()).index(0)]\n",
    "                used.append(ocr_label)\n",
    "                #print(ocr_label)\n",
    "                        \n",
    "                m.ocr_label = ocr_label\n",
    "        else:\n",
    "            print('zero length eds', m)\n",
    "        #print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ochre.matchlines import UNKNOWN, EMPTY\n",
    "\n",
    "def match_close(matches, ocr_lines, used):\n",
    "\n",
    "    for m in matches:\n",
    "        if m.ocr_label == UNKNOWN:\n",
    "            #print(m)\n",
    "            ocr_label = m.get_match(ocr_lines, matches, used, method='close')\n",
    "            m.ocr_label = ocr_label\n",
    "            if ocr_label != UNKNOWN and ocr_label != EMPTY:\n",
    "                used.append(ocr_label)\n",
    "            #print(m)\n",
    "    \n",
    "    if count_unknown(matches) == len(matches):\n",
    "        #print('Everything still unknown, so matching best')\n",
    "        for m in matches:\n",
    "            #print(m)\n",
    "            #print('next:', m.next)\n",
    "            ocr_label = m.get_match(ocr_lines, matches, used, method='best')\n",
    "            m.ocr_label = ocr_label\n",
    "            #print('Using', ocr_label)\n",
    "            if ocr_label != UNKNOWN and ocr_label != EMPTY:\n",
    "                used.append(ocr_label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaps(matches):\n",
    "    unknowns = []\n",
    "    gs_labels = []\n",
    "    unk = False\n",
    "\n",
    "    for m in matches:\n",
    "        if m.ocr_label == UNKNOWN:\n",
    "            unk = True\n",
    "            unknowns.append(m)\n",
    "            gs_labels.append(m.gs_label)\n",
    "        elif unk:\n",
    "            yield unknowns, gs_labels\n",
    "            unk = False\n",
    "            unknowns = []\n",
    "            gs_labels = []\n",
    "    if unk:\n",
    "        yield unknowns, gs_labels\n",
    "\n",
    "def match_gaps(matches, used, ocr_lines):\n",
    "    #print('match gaps')\n",
    "    #print([g for g in gaps(matches)])\n",
    "    for unknowns, gs_labels in gaps(matches):\n",
    "        if len(unknowns) > 0:\n",
    "            #print(len(gs_labels), len(unknowns))\n",
    "    \n",
    "            if len(unknowns) > 0 and len(unknowns) == len(gs_labels):\n",
    "                if unknowns[0].previous is not None:\n",
    "                    start_index = list(ocr_lines.keys()).index(unknowns[0].previous.ocr_label) + 1\n",
    "                else: \n",
    "                    start_index = 0\n",
    "                    \n",
    "                if unknowns[-1].next is not None:\n",
    "                    stop_index = list(ocr_lines.keys()).index(unknowns[-1].next.ocr_label)\n",
    "                else:\n",
    "                    stop_index = unknowns[-1].index + 1\n",
    "                #print('start - stop', start_index, stop_index)\n",
    "                #print([i for i in range(start_index, stop_index)])\n",
    "                options = []\n",
    "                for i in range(start_index, stop_index):\n",
    "                    try:\n",
    "                        options.append(list(ocr_lines.keys())[i])\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "                p_options = []\n",
    "                #print('unknowns', unknowns)\n",
    "                for u in unknowns:\n",
    "                    #print('u', u)\n",
    "                    #print('get_options', u.get_options(ocr_lines, used).keys())\n",
    "                    for o in u.get_options(ocr_lines, used).keys():\n",
    "                        #print(o)\n",
    "                        if o not in p_options:\n",
    "                            p_options.append(o)\n",
    "                #print('possible options', p_options)\n",
    "                if len(p_options) == len(gs_labels):\n",
    "                #    print(options)\n",
    "                #    print(set(options).intersection(set(used)))\n",
    "                    if len(set(options).intersection(set(used))) == 0:\n",
    "                        for m, ocr_label in zip(unknowns, p_options):\n",
    "                            #print(m)\n",
    "                            #print(list(ocr_lines.keys())[i])\n",
    "                            m.ocr_label = ocr_label\n",
    "                            used.append(ocr_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_match_best(matches, used, ocr_lines):\n",
    "    prev_unknown = len(matches)\n",
    "    num_unknown = count_unknown(matches)\n",
    "    \n",
    "    while num_unknown < prev_unknown:\n",
    "        for m in matches:\n",
    "            if m.ocr_label == UNKNOWN:\n",
    "                #print(m)\n",
    "                ocr_label = m.get_match(ocr_lines, matches, used, method='best')\n",
    "                m.ocr_label = ocr_label\n",
    "                if ocr_label != UNKNOWN and ocr_label != EMPTY:\n",
    "                    used.append(ocr_label)\n",
    "                #print(m)\n",
    "        prev_unknown = num_unknown\n",
    "        num_unknown = count_unknown(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def edlib2pair(query: str, ref: str, mode: str = \"NW\") -> str:\n",
    "    \"\"\"\n",
    "    input:\n",
    "    query and ref sequence\n",
    "\n",
    "    output:\n",
    "    TAAGGATGGTCCCAT TC\n",
    "     ||||  ||||.||| ||\n",
    "     AAGG  GGTCTCATATC\n",
    "    \"\"\"\n",
    "\n",
    "    a = edlib.align(query, ref, mode=mode, task=\"path\")\n",
    "    ref_pos = a[\"locations\"][0][0]\n",
    "    query_pos = 0\n",
    "    ref_aln = []\n",
    "    match_aln = \"\"\n",
    "    query_aln = []\n",
    "\n",
    "    for step, code in re.findall(r\"(\\d+)(\\D)\", a[\"cigar\"]):\n",
    "        step = int(step)\n",
    "        if code == \"=\":\n",
    "            for c in ref[ref_pos : ref_pos + step]:\n",
    "                ref_aln.append(c)\n",
    "            #ref_aln += ref[ref_pos : ref_pos + step]\n",
    "            ref_pos += step\n",
    "            for c in query[query_pos : query_pos + step]:\n",
    "                query_aln.append(c)\n",
    "            #query_aln += query[query_pos : query_pos + step]\n",
    "            query_pos += step\n",
    "            match_aln += \"|\" * step\n",
    "        elif code == \"X\":\n",
    "            for c in ref[ref_pos : ref_pos + step]:\n",
    "                ref_aln.append(c)\n",
    "            #ref_aln += ref[ref_pos : ref_pos + step]\n",
    "            ref_pos += step\n",
    "            for c in query[query_pos : query_pos + step]:\n",
    "                query_aln.append(c)\n",
    "            #query_aln += query[query_pos : query_pos + step]\n",
    "            query_pos += step\n",
    "            match_aln += \".\" * step\n",
    "        elif code == \"D\":\n",
    "            for c in ref[ref_pos : ref_pos + step]:\n",
    "                ref_aln.append(c)\n",
    "            #ref_aln += ref[ref_pos : ref_pos + step]\n",
    "            ref_pos += step\n",
    "            #query_aln += \" \" * step\n",
    "            query_pos += 0\n",
    "            for i in range(step):\n",
    "                query_aln.append('')\n",
    "            match_aln += \" \" * step\n",
    "        elif code == \"I\":\n",
    "            for i in range(step):\n",
    "                ref_aln.append('')\n",
    "            #ref_aln += \" \" * step\n",
    "            ref_pos += 0\n",
    "            for c in query[query_pos : query_pos + step]:\n",
    "                query_aln.append(c)\n",
    "            #query_aln += query[query_pos : query_pos + step]\n",
    "            query_pos += step\n",
    "            match_aln += \" \" * step\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return ref_aln, match_aln, query_aln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edlib\n",
    "import json\n",
    "\n",
    "from nlppln.utils import create_dirs, out_file_name\n",
    "from ochre.utils import align_characters\n",
    "\n",
    "def align_page(matches):\n",
    "    ocr_result = []\n",
    "    gs_result = []\n",
    "    \n",
    "    for m in matches:\n",
    "        print(m)\n",
    "\n",
    "    for m in matches:\n",
    "        gs = ' '.join(gs_lines[m.gs_label])\n",
    "        ocr = ' '.join(ocr_lines.get(m.ocr_label, ''))\n",
    "    \n",
    "        print(' GS:', repr(gs))\n",
    "        print('OCR:', repr(ocr))\n",
    "        print(len(gs), len(ocr))\n",
    "        \n",
    "        if len(gs) == 0:\n",
    "            if len(ocr) != 0:\n",
    "                #print(m)\n",
    "                #print(' GS:', repr(gs))\n",
    "                #print('OCR:', repr(ocr))\n",
    "                #print(len(gs), len(ocr))\n",
    "                for c in ocr:\n",
    "                    ocr_result.append(c)\n",
    "                    gs_result.append('')\n",
    "        else:\n",
    "            gs_a, match_a, ocr_a = edlib2pair(ocr, gs, mode='NW')\n",
    "            if len(ocr_a) != len(gs_a):\n",
    "                print('UNEQUAL!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        \n",
    "            for o, g in zip(ocr_a, gs_a):\n",
    "                ocr_result.append(o)\n",
    "                gs_result.append(g)\n",
    "        #    print(o,g)\n",
    "        #print('---')\n",
    "    return gs_result, ocr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_block(gs_text, ocr_text):\n",
    "    if gs_text != '' and ocr_text != '':\n",
    "        gs_a, match_a, ocr_a = edlib2pair(ocr_text, gs_text, mode='NW')\n",
    "    else:\n",
    "        print('Empty stuff!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        if gs_text == '' and ocr_text == '':\n",
    "            gs_a = []\n",
    "            ocr_a = []\n",
    "        elif ocr_text != '':\n",
    "            gs_a = []\n",
    "            ocr_a = []\n",
    "            for c in ocr_text:\n",
    "                gs_a.append('')\n",
    "                ocr_a.append(c)\n",
    "        else:\n",
    "            gs_a = []\n",
    "            ocr_a = []\n",
    "            for c in gs_text:\n",
    "                gs_a.append(c)\n",
    "                ocr_a.append('')\n",
    "        print('Returning')\n",
    "        print(gs_a)\n",
    "        print(ocr_a)\n",
    "\n",
    "    return gs_a, ocr_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ochre.matchlines import get_ns, replace_entities\n",
    "from ochre.utils import get_temp_file\n",
    "\n",
    "from nlppln.utils import create_dirs, out_file_name\n",
    "\n",
    "def do_matching(gs_lines, ocr_lines):\n",
    "    #print('Number of lines in gs', len(gs_lines))\n",
    "    #print('Number of lines in ocr', len(ocr_lines))\n",
    "\n",
    "    matches = initialize_matches(gs_lines, ocr_lines)\n",
    "    \n",
    "    #print('Printing matches (init):')\n",
    "    #for m in matches:\n",
    "    #    print(m)\n",
    "    #print('---')\n",
    "    #print('len matches after init', len(matches))\n",
    "        \n",
    "    used = []\n",
    "    set_zero(matches, used)\n",
    "    \n",
    "    #num_unknown = count_unknown(matches)\n",
    "    #print('Unknown after set zero:', num_unknown)\n",
    "    \n",
    "    #print('Printing matches (set zero):')\n",
    "    #for m in matches:\n",
    "    #    print(m)\n",
    "    #print('---')\n",
    "    \n",
    "    match_close(matches, ocr_lines, used)\n",
    "    \n",
    "    #num_unknown = count_unknown(matches)\n",
    "    #print('Unknown after match close:', num_unknown)\n",
    "    \n",
    "    #match_gaps(matches, used, ocr_lines)\n",
    "    \n",
    "    #num_unknown = count_unknown(matches)\n",
    "    #print('Unknown after match gaps:', num_unknown)\n",
    "    \n",
    "    #repeat_match_best(matches, used, ocr_lines)\n",
    "    \n",
    "    #num_unknown = count_unknown(matches)\n",
    "    #print('Unknown after match gaps:', num_unknown)\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "from nlppln.utils import get_files, create_dirs, out_file_name\n",
    "\n",
    "from ochre.utils import get_temp_file\n",
    "from ochre.matchlines import replace_entities\n",
    "\n",
    "# inladen json\n",
    "# vind gs_file en ocr_file\n",
    "# Maak datastructuur met textblock_id -> ordered dict met textline ids -> word lists\n",
    "\n",
    "json_dir = '/home/jvdzwaan/data/kb-ocr/textblock_matches-original-altos/'\n",
    "gs_dir = '/home/jvdzwaan/ownCloud/Shared/OCR/Ground-truth/'\n",
    "ocr_dir = '/home/jvdzwaan/ownCloud/Shared/OCR/Originele ALTOs/'\n",
    "\n",
    "out_dir = '/home/jvdzwaan/data/kb-ocr/text_aligned_blocks-match_gs'\n",
    "\n",
    "json_files = get_files(json_dir)\n",
    "#json_files = ['/home/jvdzwaan/data/kb-ocr/textblock_matches-original-altos/DDD_010017911_002.json']\n",
    "print(len(json_files))\n",
    "for in_file in tqdm(json_files):\n",
    "    print(in_file)\n",
    "    bn = os.path.splitext(os.path.basename(in_file))[0]\n",
    "    gs_file = glob.glob('{}*'.format(os.path.join(gs_dir, bn)))[0]\n",
    "    gs_tmp = get_temp_file()\n",
    "    #print(gs_tmp)\n",
    "    with open(gs_tmp, 'w') as f:\n",
    "        f.write(replace_entities(gs_file))\n",
    "    \n",
    "    ocr_file = glob.glob('{}*'.format(os.path.join(ocr_dir, bn)))[0]\n",
    "    \n",
    "    with open(in_file) as f:\n",
    "        tb_matches = json.load(f)\n",
    "    \n",
    "    #print(tb_matches)\n",
    "    \n",
    "    gs_blocks = get_textblocks_lines(gs_tmp)\n",
    "    ocr_blocks = get_textblocks_lines(ocr_file)\n",
    "    \n",
    "    print('# textblocks', len(gs_blocks), len(ocr_blocks))\n",
    "    #print(gs_blocks)\n",
    "    \n",
    "    os.remove(gs_tmp)\n",
    "    \n",
    "    gs_text = []\n",
    "    ocr_text = []\n",
    "    gs_aligned = []\n",
    "    ocr_aligned = []\n",
    "    \n",
    "    for gs_block_id, ocr_block_id in tb_matches.items():\n",
    "        #print(gs_block_id, ocr_block_id)\n",
    "        if ocr_block_id is not None:\n",
    "            #print(gs_blocks[gs_block_id])\n",
    "            gs_lines = gs_blocks[gs_block_id]\n",
    "            ocr_lines = ocr_blocks[ocr_block_id]\n",
    "            #print(len(gs_lines))\n",
    "            #print(gs_lines)\n",
    "            #print(len(ocr_lines))\n",
    "            #print(ocr_lines)\n",
    "            matches = do_matching(gs_lines, ocr_lines)\n",
    "            \n",
    "            gs_to_align = []\n",
    "            ocr_to_align = []\n",
    "            \n",
    "            # save gs text, ocr text and aligned\n",
    "            #print('Matches')\n",
    "            for m in matches:\n",
    "                #print(m)\n",
    "                if m.ocr_label != UNKNOWN and m.ocr_label != EMPTY:\n",
    "                    gs_text.append(' '.join(gs_lines[m.gs_label]))\n",
    "                    ocr_text.append(' '.join(ocr_lines[m.ocr_label]))\n",
    "                    \n",
    "                    gs_to_align.append(' '.join(gs_lines[m.gs_label]))\n",
    "                    ocr_to_align.append(' '.join(ocr_lines[m.ocr_label]))\n",
    "                    \n",
    "            #print(m.gs_label, m.ocr_label)\n",
    "            gs_a, ocr_a = align_block(' '.join(gs_to_align), ' '.join(ocr_to_align))\n",
    "            gs_aligned.append(gs_a)\n",
    "            ocr_aligned.append(ocr_a)\n",
    "            \n",
    "\n",
    "    # write gs text\n",
    "    out_file = out_file_name(os.path.join(out_dir, 'gs'), in_file, 'txt')\n",
    "    print(out_file)\n",
    "    create_dirs(out_file, is_file=True)\n",
    "    with open(out_file, 'w') as f:\n",
    "        f.write(' '.join(gs_text))\n",
    "            \n",
    "    \n",
    "    # write ocr text\n",
    "    out_file = out_file_name(os.path.join(out_dir, 'ocr'), in_file, 'txt')\n",
    "    print(out_file)\n",
    "    create_dirs(out_file, is_file=True)\n",
    "    with open(out_file, 'w') as f:\n",
    "        f.write(' '.join(ocr_text))\n",
    "    \n",
    "    # write aligned\n",
    "    gs_a = []\n",
    "    for tb in gs_aligned:\n",
    "        for c in tb:\n",
    "            gs_a.append(c)\n",
    "    ocr_a = []\n",
    "    for tb in ocr_aligned:\n",
    "        for c in tb:\n",
    "            ocr_a.append(c)\n",
    "            \n",
    "    if len(gs_a) != len(ocr_a):\n",
    "        print('unequal lengths for aligned')\n",
    "        break\n",
    "    \n",
    "    out_file = out_file_name(os.path.join(out_dir, 'aligned'), in_file, 'json')\n",
    "    print(out_file)\n",
    "    create_dirs(out_file, is_file=True)\n",
    "    with open(out_file, 'w') as f:\n",
    "        json.dump({'ocr': ocr_a, 'gs': gs_a}, f)\n",
    "        \n",
    "    print()\n",
    "    #break"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
